{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep belief network for bimodal embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import theano\n",
    "from array import array\n",
    "\n",
    "# Local package\n",
    "from DBN import DBN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numpy_rng = np.random.RandomState(123)\n",
    "\n",
    "# construct the Deep Belief Network\n",
    "dbn = DBN(numpy_rng=numpy_rng, n_ins=50, hidden_layers_sizes=[5000, 1000, 100], n_outs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefvectors = pd.read_csv('prefvectors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from array import array\n",
    "X = prefvectors.factors.apply(lambda x: np.array(eval(x)))\n",
    "shared_x = theano.shared(np.asarray(list(X), dtype=theano.config.floatX), borrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training layer 0, epoch 0, cost  -2.47055\n",
      "Pre-training layer 0, epoch 1, cost  -0.0122099\n",
      "Pre-training layer 0, epoch 2, cost  -0.0110026\n",
      "Pre-training layer 0, epoch 3, cost  -0.00915137\n",
      "Pre-training layer 0, epoch 4, cost  -0.00493256\n",
      "Pre-training layer 0, epoch 5, cost  -0.00767487\n",
      "Pre-training layer 0, epoch 6, cost  -0.00787691\n",
      "Pre-training layer 0, epoch 7, cost  -0.00625344\n",
      "Pre-training layer 0, epoch 8, cost  -0.00635216\n",
      "Pre-training layer 0, epoch 9, cost  -0.00577203\n",
      "Pre-training layer 0, epoch 10, cost  -0.00642714\n",
      "Pre-training layer 0, epoch 11, cost  -0.0055519\n",
      "Pre-training layer 0, epoch 12, cost  -0.00509081\n",
      "Pre-training layer 0, epoch 13, cost  -0.00447211\n",
      "Pre-training layer 0, epoch 14, cost  -0.00469298\n",
      "Pre-training layer 0, epoch 15, cost  -0.00482907\n",
      "Pre-training layer 0, epoch 16, cost  -0.00501246\n",
      "Pre-training layer 0, epoch 17, cost  -0.00428361\n",
      "Pre-training layer 0, epoch 18, cost  -0.003839\n",
      "Pre-training layer 0, epoch 19, cost  -0.00347021\n",
      "Pre-training layer 0, epoch 20, cost  -0.00365122\n",
      "Pre-training layer 0, epoch 21, cost  -0.00276262\n",
      "Pre-training layer 0, epoch 22, cost  -0.00481761\n",
      "Pre-training layer 0, epoch 23, cost  -0.00340524\n",
      "Pre-training layer 0, epoch 24, cost  -0.00385577\n",
      "Pre-training layer 0, epoch 25, cost  -0.00494779\n",
      "Pre-training layer 0, epoch 26, cost  -0.00330542\n",
      "Pre-training layer 0, epoch 27, cost  -0.00475823\n",
      "Pre-training layer 0, epoch 28, cost  -0.00409226\n",
      "Pre-training layer 0, epoch 29, cost  -0.00410757\n",
      "Pre-training layer 0, epoch 30, cost  -0.00402051\n",
      "Pre-training layer 0, epoch 31, cost  -0.0029079\n",
      "Pre-training layer 0, epoch 32, cost  -0.00584857\n",
      "Pre-training layer 0, epoch 33, cost  -0.0056117\n",
      "Pre-training layer 0, epoch 34, cost  -0.00308301\n",
      "Pre-training layer 0, epoch 35, cost  -0.00531984\n",
      "Pre-training layer 0, epoch 36, cost  -0.00301453\n",
      "Pre-training layer 0, epoch 37, cost  -0.00416889\n",
      "Pre-training layer 0, epoch 38, cost  -0.000848748\n",
      "Pre-training layer 0, epoch 39, cost  -0.00254975\n",
      "Pre-training layer 0, epoch 40, cost  -0.00438891\n",
      "Pre-training layer 0, epoch 41, cost  -0.00346262\n",
      "Pre-training layer 0, epoch 42, cost  -0.00368291\n",
      "Pre-training layer 0, epoch 43, cost  -0.00282422\n",
      "Pre-training layer 0, epoch 44, cost  -0.00573357\n",
      "Pre-training layer 0, epoch 45, cost  -0.00348697\n",
      "Pre-training layer 0, epoch 46, cost  -0.00617513\n",
      "Pre-training layer 0, epoch 47, cost  -0.00447123\n",
      "Pre-training layer 0, epoch 48, cost  -0.00353875\n",
      "Pre-training layer 0, epoch 49, cost  -0.00272599\n",
      "Pre-training layer 0, epoch 50, cost  -0.0020758\n",
      "Pre-training layer 0, epoch 51, cost  -0.00353248\n",
      "Pre-training layer 0, epoch 52, cost  -0.00549866\n",
      "Pre-training layer 0, epoch 53, cost  -0.00230737\n",
      "Pre-training layer 0, epoch 54, cost  -0.00288584\n",
      "Pre-training layer 0, epoch 55, cost  -0.00290685\n",
      "Pre-training layer 0, epoch 56, cost  -0.00296903\n",
      "Pre-training layer 0, epoch 57, cost  -0.00391257\n",
      "Pre-training layer 0, epoch 58, cost  -0.00308987\n",
      "Pre-training layer 0, epoch 59, cost  -0.00359224\n",
      "Pre-training layer 0, epoch 60, cost  -0.0042924\n",
      "Pre-training layer 0, epoch 61, cost  -0.00253052\n",
      "Pre-training layer 0, epoch 62, cost  -0.00296356\n",
      "Pre-training layer 0, epoch 63, cost  -0.00178151\n",
      "Pre-training layer 0, epoch 64, cost  -0.0026786\n",
      "Pre-training layer 0, epoch 65, cost  -0.00430072\n",
      "Pre-training layer 0, epoch 66, cost  -0.00290195\n",
      "Pre-training layer 0, epoch 67, cost  -0.0053185\n",
      "Pre-training layer 0, epoch 68, cost  -0.00528156\n",
      "Pre-training layer 0, epoch 69, cost  -0.00397658\n",
      "Pre-training layer 0, epoch 70, cost  -0.00345618\n",
      "Pre-training layer 0, epoch 71, cost  -0.00482575\n",
      "Pre-training layer 0, epoch 72, cost  -0.00209863\n",
      "Pre-training layer 0, epoch 73, cost  -0.00437175\n",
      "Pre-training layer 0, epoch 74, cost  -0.00326076\n",
      "Pre-training layer 0, epoch 75, cost  -0.00262672\n",
      "Pre-training layer 0, epoch 76, cost  -0.0035917\n",
      "Pre-training layer 0, epoch 77, cost  -0.00403584\n",
      "Pre-training layer 0, epoch 78, cost  -0.00446413\n",
      "Pre-training layer 0, epoch 79, cost  -0.00258161\n",
      "Pre-training layer 0, epoch 80, cost  -0.00178049\n",
      "Pre-training layer 0, epoch 81, cost  -0.00457653\n",
      "Pre-training layer 0, epoch 82, cost  -0.00210514\n",
      "Pre-training layer 0, epoch 83, cost  -0.00328087\n",
      "Pre-training layer 0, epoch 84, cost  -0.00384741\n",
      "Pre-training layer 0, epoch 85, cost  -0.00309916\n",
      "Pre-training layer 0, epoch 86, cost  -0.00533762\n",
      "Pre-training layer 0, epoch 87, cost  -0.00340591\n",
      "Pre-training layer 0, epoch 88, cost  -0.00450919\n",
      "Pre-training layer 0, epoch 89, cost  -0.00471526\n",
      "Pre-training layer 0, epoch 90, cost  -0.00194767\n",
      "Pre-training layer 0, epoch 91, cost  -0.00345329\n",
      "Pre-training layer 0, epoch 92, cost  -0.0030903\n",
      "Pre-training layer 0, epoch 93, cost  -0.00542718\n",
      "Pre-training layer 0, epoch 94, cost  -0.00193343\n",
      "Pre-training layer 0, epoch 95, cost  -0.00288766\n",
      "Pre-training layer 0, epoch 96, cost  -0.00343516\n",
      "Pre-training layer 0, epoch 97, cost  -0.00267591\n",
      "Pre-training layer 0, epoch 98, cost  -0.00358968\n",
      "Pre-training layer 0, epoch 99, cost  -0.0033265\n",
      "Pre-training layer 0, epoch 100, cost  -0.00300921\n",
      "Pre-training layer 0, epoch 101, cost  -0.00459174\n",
      "Pre-training layer 0, epoch 102, cost  -0.00429696\n",
      "Pre-training layer 0, epoch 103, cost  -0.00171064\n",
      "Pre-training layer 0, epoch 104, cost  -0.00511906\n",
      "Pre-training layer 0, epoch 105, cost  -0.00425968\n",
      "Pre-training layer 0, epoch 106, cost  -0.00283912\n",
      "Pre-training layer 0, epoch 107, cost  -0.00431533\n",
      "Pre-training layer 0, epoch 108, cost  -0.00283505\n",
      "Pre-training layer 0, epoch 109, cost  -0.00380933\n",
      "Pre-training layer 0, epoch 110, cost  -0.00239666\n",
      "Pre-training layer 0, epoch 111, cost  -0.00290381\n",
      "Pre-training layer 0, epoch 112, cost  -0.0042807\n",
      "Pre-training layer 0, epoch 113, cost  -0.00415869\n",
      "Pre-training layer 0, epoch 114, cost  -0.00165963\n",
      "Pre-training layer 0, epoch 115, cost  -0.00453459\n",
      "Pre-training layer 0, epoch 116, cost  -0.00423647\n",
      "Pre-training layer 0, epoch 117, cost  -0.00255321\n",
      "Pre-training layer 0, epoch 118, cost  -0.002132\n",
      "Pre-training layer 0, epoch 119, cost  -0.00266782\n",
      "Pre-training layer 0, epoch 120, cost  -0.00177445\n",
      "Pre-training layer 0, epoch 121, cost  -0.00477706\n",
      "Pre-training layer 0, epoch 122, cost  -0.00367113\n",
      "Pre-training layer 0, epoch 123, cost  -0.00255775\n",
      "Pre-training layer 0, epoch 124, cost  -0.00240496\n",
      "Pre-training layer 0, epoch 125, cost  -0.00416493\n",
      "Pre-training layer 0, epoch 126, cost  -0.00233598\n",
      "Pre-training layer 0, epoch 127, cost  -0.000593186\n",
      "Pre-training layer 0, epoch 128, cost  -0.00495813\n",
      "Pre-training layer 0, epoch 129, cost  -0.00277838\n",
      "Pre-training layer 0, epoch 130, cost  -0.00263421\n",
      "Pre-training layer 0, epoch 131, cost  -0.00275869\n",
      "Pre-training layer 0, epoch 132, cost  -0.00424718\n",
      "Pre-training layer 0, epoch 133, cost  -0.00440928\n",
      "Pre-training layer 0, epoch 134, cost  -0.00184558\n",
      "Pre-training layer 0, epoch 135, cost  -0.0021482\n",
      "Pre-training layer 0, epoch 136, cost  -0.00322894\n",
      "Pre-training layer 0, epoch 137, cost  -0.00375145\n",
      "Pre-training layer 0, epoch 138, cost  -0.00320243\n",
      "Pre-training layer 0, epoch 139, cost  -0.00383485\n",
      "Pre-training layer 0, epoch 140, cost  -0.00431309\n",
      "Pre-training layer 0, epoch 141, cost  -0.00311401\n",
      "Pre-training layer 0, epoch 142, cost  -0.00368407\n",
      "Pre-training layer 0, epoch 143, cost  -0.00256256\n",
      "Pre-training layer 0, epoch 144, cost  -0.00424091\n",
      "Pre-training layer 0, epoch 145, cost  -0.00465856\n",
      "Pre-training layer 0, epoch 146, cost  -0.00493915\n",
      "Pre-training layer 0, epoch 147, cost  -0.00510451\n",
      "Pre-training layer 0, epoch 148, cost  -0.00117855\n",
      "Pre-training layer 0, epoch 149, cost  -0.0037503\n",
      "Pre-training layer 0, epoch 150, cost  -0.00359305\n",
      "Pre-training layer 0, epoch 151, cost  -0.00299492\n",
      "Pre-training layer 0, epoch 152, cost  -0.0043024\n",
      "Pre-training layer 0, epoch 153, cost  -0.00393379\n",
      "Pre-training layer 0, epoch 154, cost  -0.00409326\n",
      "Pre-training layer 0, epoch 155, cost  -0.00461022\n",
      "Pre-training layer 0, epoch 156, cost  -0.00376663\n",
      "Pre-training layer 0, epoch 157, cost  -0.00338378\n",
      "Pre-training layer 0, epoch 158, cost  -0.0026293\n",
      "Pre-training layer 0, epoch 159, cost  -0.00314209\n",
      "Pre-training layer 0, epoch 160, cost  -0.00320847\n",
      "Pre-training layer 0, epoch 161, cost  -0.00309792\n",
      "Pre-training layer 0, epoch 162, cost  -0.00398848\n",
      "Pre-training layer 0, epoch 163, cost  -0.00262435\n",
      "Pre-training layer 0, epoch 164, cost  -0.00287208\n",
      "Pre-training layer 0, epoch 165, cost  -0.00250562\n",
      "Pre-training layer 0, epoch 166, cost  -0.0043955\n",
      "Pre-training layer 0, epoch 167, cost  -0.00412477\n",
      "Pre-training layer 0, epoch 168, cost  -0.0029009\n",
      "Pre-training layer 0, epoch 169, cost  -0.00497459\n",
      "Pre-training layer 0, epoch 170, cost  -0.0048889\n",
      "Pre-training layer 0, epoch 171, cost  -0.00345659\n",
      "Pre-training layer 0, epoch 172, cost  -0.00332638\n",
      "Pre-training layer 0, epoch 173, cost  -0.00311525\n",
      "Pre-training layer 0, epoch 174, cost  -0.00188226\n",
      "Pre-training layer 0, epoch 175, cost  -0.0027519\n",
      "Pre-training layer 0, epoch 176, cost  -0.00137191\n",
      "Pre-training layer 0, epoch 177, cost  -0.00337545\n",
      "Pre-training layer 0, epoch 178, cost  -0.00409171\n",
      "Pre-training layer 0, epoch 179, cost  -0.00249999\n",
      "Pre-training layer 0, epoch 180, cost  -0.0031007\n",
      "Pre-training layer 0, epoch 181, cost  -0.00154908\n",
      "Pre-training layer 0, epoch 182, cost  -0.00287567\n",
      "Pre-training layer 0, epoch 183, cost  -0.00301363\n",
      "Pre-training layer 0, epoch 184, cost  -0.00243551\n",
      "Pre-training layer 0, epoch 185, cost  -0.00230666\n",
      "Pre-training layer 0, epoch 186, cost  -0.00266655\n",
      "Pre-training layer 0, epoch 187, cost  -0.00417047\n",
      "Pre-training layer 0, epoch 188, cost  -0.00383842\n",
      "Pre-training layer 0, epoch 189, cost  -0.00395828\n",
      "Pre-training layer 0, epoch 190, cost  -0.0031291\n",
      "Pre-training layer 0, epoch 191, cost  -0.00272028\n",
      "Pre-training layer 0, epoch 192, cost  -0.00354642\n",
      "Pre-training layer 0, epoch 193, cost  -0.00366253\n",
      "Pre-training layer 0, epoch 194, cost  -0.00329404\n",
      "Pre-training layer 0, epoch 195, cost  -0.00362746\n",
      "Pre-training layer 0, epoch 196, cost  -0.00216231\n",
      "Pre-training layer 0, epoch 197, cost  -0.00366795\n",
      "Pre-training layer 0, epoch 198, cost  -0.00348949\n",
      "Pre-training layer 0, epoch 199, cost  -0.00345507\n",
      "Pre-training layer 0, epoch 200, cost  -0.00303923\n",
      "Pre-training layer 0, epoch 201, cost  -0.00451011\n",
      "Pre-training layer 0, epoch 202, cost  -0.00289439\n",
      "Pre-training layer 0, epoch 203, cost  -0.00391492\n",
      "Pre-training layer 0, epoch 204, cost  -0.002868\n",
      "Pre-training layer 0, epoch 205, cost  -0.00292005\n",
      "Pre-training layer 0, epoch 206, cost  -0.00109989\n",
      "Pre-training layer 0, epoch 207, cost  -0.00271307\n",
      "Pre-training layer 0, epoch 208, cost  -0.00380056\n",
      "Pre-training layer 0, epoch 209, cost  -0.0042545\n",
      "Pre-training layer 0, epoch 210, cost  -0.00226433\n",
      "Pre-training layer 0, epoch 211, cost  -0.00432062\n",
      "Pre-training layer 0, epoch 212, cost  -0.00341474\n",
      "Pre-training layer 0, epoch 213, cost  -0.00322458\n",
      "Pre-training layer 0, epoch 214, cost  -0.0019374\n",
      "Pre-training layer 0, epoch 215, cost  -0.00333455\n",
      "Pre-training layer 0, epoch 216, cost  -0.00327783\n",
      "Pre-training layer 0, epoch 217, cost  -0.00279042\n",
      "Pre-training layer 0, epoch 218, cost  -0.00527962\n",
      "Pre-training layer 0, epoch 219, cost  -0.00312469\n",
      "Pre-training layer 0, epoch 220, cost  -0.00263508\n",
      "Pre-training layer 0, epoch 221, cost  -0.00322995\n",
      "Pre-training layer 0, epoch 222, cost  -0.00452373\n",
      "Pre-training layer 0, epoch 223, cost  -0.00102086\n",
      "Pre-training layer 0, epoch 224, cost  -0.0025495\n",
      "Pre-training layer 0, epoch 225, cost  -0.00206001\n",
      "Pre-training layer 0, epoch 226, cost  -0.00200077\n",
      "Pre-training layer 0, epoch 227, cost  -0.00385832\n",
      "Pre-training layer 0, epoch 228, cost  -0.00515759\n",
      "Pre-training layer 0, epoch 229, cost  -0.00289235\n",
      "Pre-training layer 0, epoch 230, cost  -0.00325186\n",
      "Pre-training layer 0, epoch 231, cost  -0.00338008\n",
      "Pre-training layer 0, epoch 232, cost  -0.0019018\n",
      "Pre-training layer 0, epoch 233, cost  -0.0025843\n",
      "Pre-training layer 0, epoch 234, cost  -0.00384451\n",
      "Pre-training layer 0, epoch 235, cost  -0.00469449\n",
      "Pre-training layer 0, epoch 236, cost  -0.00422393\n",
      "Pre-training layer 0, epoch 237, cost  -0.0041842\n",
      "Pre-training layer 0, epoch 238, cost  -0.00260672\n",
      "Pre-training layer 0, epoch 239, cost  -0.00302464\n",
      "Pre-training layer 0, epoch 240, cost  -0.00472109\n",
      "Pre-training layer 0, epoch 241, cost  -0.00201081\n",
      "Pre-training layer 0, epoch 242, cost  -0.00544665\n",
      "Pre-training layer 0, epoch 243, cost  -0.00293143\n",
      "Pre-training layer 0, epoch 244, cost  -0.0028547\n",
      "Pre-training layer 0, epoch 245, cost  -0.0019368\n",
      "Pre-training layer 0, epoch 246, cost  -0.00356119\n",
      "Pre-training layer 0, epoch 247, cost  -0.00263748\n",
      "Pre-training layer 0, epoch 248, cost  -0.00194511\n",
      "Pre-training layer 0, epoch 249, cost  -0.00372041\n",
      "Pre-training layer 0, epoch 250, cost  -0.00278692\n",
      "Pre-training layer 0, epoch 251, cost  -0.00350914\n",
      "Pre-training layer 0, epoch 252, cost  -0.0033657\n",
      "Pre-training layer 0, epoch 253, cost  -0.00388914\n",
      "Pre-training layer 0, epoch 254, cost  -0.000409968\n",
      "Pre-training layer 0, epoch 255, cost  -0.00138388\n",
      "Pre-training layer 0, epoch 256, cost  -0.00118541\n",
      "Pre-training layer 0, epoch 257, cost  -0.00256633\n",
      "Pre-training layer 0, epoch 258, cost  -0.0030285\n",
      "Pre-training layer 0, epoch 259, cost  -0.00226315\n",
      "Pre-training layer 0, epoch 260, cost  -0.00310619\n",
      "Pre-training layer 0, epoch 261, cost  -0.00342125\n",
      "Pre-training layer 0, epoch 262, cost  -0.00201458\n",
      "Pre-training layer 0, epoch 263, cost  -0.00390239\n",
      "Pre-training layer 0, epoch 264, cost  -0.0028274\n",
      "Pre-training layer 0, epoch 265, cost  -0.00358877\n",
      "Pre-training layer 0, epoch 266, cost  -0.00285253\n",
      "Pre-training layer 0, epoch 267, cost  -0.000853017\n",
      "Pre-training layer 0, epoch 268, cost  -0.00286379\n",
      "Pre-training layer 0, epoch 269, cost  -0.00283132\n",
      "Pre-training layer 0, epoch 270, cost  -0.00369265\n",
      "Pre-training layer 0, epoch 271, cost  -0.00269198\n",
      "Pre-training layer 0, epoch 272, cost  -0.00112799\n",
      "Pre-training layer 0, epoch 273, cost  -0.00255151\n",
      "Pre-training layer 0, epoch 274, cost  -0.00347491\n",
      "Pre-training layer 0, epoch 275, cost  -0.00280113\n",
      "Pre-training layer 0, epoch 276, cost  -0.00204534\n",
      "Pre-training layer 0, epoch 277, cost  -0.000712137\n",
      "Pre-training layer 0, epoch 278, cost  -0.00285955\n",
      "Pre-training layer 0, epoch 279, cost  -0.00264916\n",
      "Pre-training layer 0, epoch 280, cost  -0.00371685\n",
      "Pre-training layer 0, epoch 281, cost  -0.00364464\n",
      "Pre-training layer 0, epoch 282, cost  -0.0033709\n",
      "Pre-training layer 0, epoch 283, cost  -0.0028173\n",
      "Pre-training layer 0, epoch 284, cost  -0.00398717\n",
      "Pre-training layer 0, epoch 285, cost  -0.00181352\n",
      "Pre-training layer 0, epoch 286, cost  -0.00339014\n",
      "Pre-training layer 0, epoch 287, cost  -0.00434695\n",
      "Pre-training layer 0, epoch 288, cost  -0.00351515\n",
      "Pre-training layer 0, epoch 289, cost  -0.00190097\n",
      "Pre-training layer 0, epoch 290, cost  -0.00349933\n",
      "Pre-training layer 0, epoch 291, cost  -0.00273115\n",
      "Pre-training layer 0, epoch 292, cost  -0.00307689\n",
      "Pre-training layer 0, epoch 293, cost  -0.00232772\n",
      "Pre-training layer 0, epoch 294, cost  -0.00198564\n",
      "Pre-training layer 0, epoch 295, cost  -0.00209564\n",
      "Pre-training layer 0, epoch 296, cost  -0.00213571\n",
      "Pre-training layer 0, epoch 297, cost  -0.00259738\n",
      "Pre-training layer 0, epoch 298, cost  -0.00399315\n",
      "Pre-training layer 0, epoch 299, cost  -0.0028653\n",
      "Pre-training layer 0, epoch 300, cost  -0.00304966\n",
      "Pre-training layer 0, epoch 301, cost  -0.0034137\n",
      "Pre-training layer 0, epoch 302, cost  -0.00234212\n",
      "Pre-training layer 0, epoch 303, cost  -0.00224993\n",
      "Pre-training layer 0, epoch 304, cost  -0.00166846\n",
      "Pre-training layer 0, epoch 305, cost  -0.00193337\n",
      "Pre-training layer 0, epoch 306, cost  -0.00212719\n",
      "Pre-training layer 0, epoch 307, cost  -0.00278438\n",
      "Pre-training layer 0, epoch 308, cost  -0.0035477\n",
      "Pre-training layer 0, epoch 309, cost  -0.00318508\n",
      "Pre-training layer 0, epoch 310, cost  -0.00326636\n",
      "Pre-training layer 0, epoch 311, cost  -0.00298895\n",
      "Pre-training layer 0, epoch 312, cost  -0.00362291\n",
      "Pre-training layer 0, epoch 313, cost  -0.0039801\n",
      "Pre-training layer 0, epoch 314, cost  -0.00379907\n",
      "Pre-training layer 0, epoch 315, cost  -0.00194541\n",
      "Pre-training layer 0, epoch 316, cost  -0.00271205\n",
      "Pre-training layer 0, epoch 317, cost  -0.00349125\n",
      "Pre-training layer 0, epoch 318, cost  -0.00183813\n",
      "Pre-training layer 0, epoch 319, cost  -0.00433978\n",
      "Pre-training layer 0, epoch 320, cost  -0.00425954\n",
      "Pre-training layer 0, epoch 321, cost  -0.00264838\n",
      "Pre-training layer 0, epoch 322, cost  -0.00345198\n",
      "Pre-training layer 0, epoch 323, cost  -0.00149857\n",
      "Pre-training layer 0, epoch 324, cost  -0.00313653\n",
      "Pre-training layer 0, epoch 325, cost  -0.00242815\n",
      "Pre-training layer 0, epoch 326, cost  -0.00221084\n",
      "Pre-training layer 0, epoch 327, cost  -0.00137862\n",
      "Pre-training layer 0, epoch 328, cost  -0.00311215\n",
      "Pre-training layer 0, epoch 329, cost  -0.00178701\n",
      "Pre-training layer 0, epoch 330, cost  -0.00198732\n",
      "Pre-training layer 0, epoch 331, cost  -0.00258483\n",
      "Pre-training layer 0, epoch 332, cost  -0.0032344\n",
      "Pre-training layer 0, epoch 333, cost  -0.00276465\n",
      "Pre-training layer 0, epoch 334, cost  -0.0025627\n",
      "Pre-training layer 0, epoch 335, cost  -0.00296305\n",
      "Pre-training layer 0, epoch 336, cost  -0.0020183\n",
      "Pre-training layer 0, epoch 337, cost  -0.00321936\n",
      "Pre-training layer 0, epoch 338, cost  -0.00382533\n",
      "Pre-training layer 0, epoch 339, cost  -0.00283422\n",
      "Pre-training layer 0, epoch 340, cost  -0.00242642\n",
      "Pre-training layer 0, epoch 341, cost  -0.00126399\n",
      "Pre-training layer 0, epoch 342, cost  -0.00371856\n",
      "Pre-training layer 0, epoch 343, cost  -0.00222103\n",
      "Pre-training layer 0, epoch 344, cost  -0.000613203\n",
      "Pre-training layer 0, epoch 345, cost  -0.00315018\n",
      "Pre-training layer 0, epoch 346, cost  -0.00218589\n",
      "Pre-training layer 0, epoch 347, cost  -0.00283751\n",
      "Pre-training layer 0, epoch 348, cost  -0.00349104\n",
      "Pre-training layer 0, epoch 349, cost  -0.00162093\n",
      "Pre-training layer 0, epoch 350, cost  -0.00320702\n",
      "Pre-training layer 0, epoch 351, cost  -0.00284463\n",
      "Pre-training layer 0, epoch 352, cost  -0.0032817\n",
      "Pre-training layer 0, epoch 353, cost  -0.00223729\n",
      "Pre-training layer 0, epoch 354, cost  -0.00345557\n",
      "Pre-training layer 0, epoch 355, cost  -0.0028102\n",
      "Pre-training layer 0, epoch 356, cost  -0.00308217\n",
      "Pre-training layer 0, epoch 357, cost  -0.00281791\n",
      "Pre-training layer 0, epoch 358, cost  -0.00238576\n",
      "Pre-training layer 0, epoch 359, cost  -0.000938412\n",
      "Pre-training layer 0, epoch 360, cost  -0.00320416\n",
      "Pre-training layer 0, epoch 361, cost  -0.00346706\n",
      "Pre-training layer 0, epoch 362, cost  -0.00334646\n",
      "Pre-training layer 0, epoch 363, cost  -0.00230753\n",
      "Pre-training layer 0, epoch 364, cost  -0.00317014\n",
      "Pre-training layer 0, epoch 365, cost  -0.00420359\n",
      "Pre-training layer 0, epoch 366, cost  -0.00209126\n",
      "Pre-training layer 0, epoch 367, cost  -0.00215668\n",
      "Pre-training layer 0, epoch 368, cost  -0.0013869\n",
      "Pre-training layer 0, epoch 369, cost  -0.0026738\n",
      "Pre-training layer 0, epoch 370, cost  -0.00367253\n",
      "Pre-training layer 0, epoch 371, cost  -0.00411093\n",
      "Pre-training layer 0, epoch 372, cost  -0.000796909\n",
      "Pre-training layer 0, epoch 373, cost  -0.00115969\n",
      "Pre-training layer 0, epoch 374, cost  -0.00243112\n",
      "Pre-training layer 0, epoch 375, cost  -0.00155025\n",
      "Pre-training layer 0, epoch 376, cost  -0.00199282\n",
      "Pre-training layer 0, epoch 377, cost  -0.00233884\n",
      "Pre-training layer 0, epoch 378, cost  -0.00267698\n",
      "Pre-training layer 0, epoch 379, cost  -0.00222647\n",
      "Pre-training layer 0, epoch 380, cost  -0.0022013\n",
      "Pre-training layer 0, epoch 381, cost  -0.00240826\n",
      "Pre-training layer 0, epoch 382, cost  -0.00303049\n",
      "Pre-training layer 0, epoch 383, cost  -0.00346653\n",
      "Pre-training layer 0, epoch 384, cost  -0.00433797\n",
      "Pre-training layer 0, epoch 385, cost  -0.00201472\n",
      "Pre-training layer 0, epoch 386, cost  -0.00411408\n",
      "Pre-training layer 0, epoch 387, cost  -0.00227241\n",
      "Pre-training layer 0, epoch 388, cost  -0.00351843\n",
      "Pre-training layer 0, epoch 389, cost  -0.00291084\n",
      "Pre-training layer 0, epoch 390, cost  -0.00160885\n",
      "Pre-training layer 0, epoch 391, cost  -0.00195471\n",
      "Pre-training layer 0, epoch 392, cost  -0.00172097\n",
      "Pre-training layer 0, epoch 393, cost  -0.0020225\n",
      "Pre-training layer 0, epoch 394, cost  -0.00255551\n",
      "Pre-training layer 0, epoch 395, cost  -0.00424501\n",
      "Pre-training layer 0, epoch 396, cost  -0.00186089\n",
      "Pre-training layer 0, epoch 397, cost  -0.00163189\n",
      "Pre-training layer 0, epoch 398, cost  -0.00460029\n",
      "Pre-training layer 0, epoch 399, cost  -0.00279557\n",
      "Pre-training layer 0, epoch 400, cost  -0.00358934\n",
      "Pre-training layer 0, epoch 401, cost  -0.00308259\n",
      "Pre-training layer 0, epoch 402, cost  -0.00126101\n",
      "Pre-training layer 0, epoch 403, cost  -0.00126229\n",
      "Pre-training layer 0, epoch 404, cost  -0.00137336\n",
      "Pre-training layer 0, epoch 405, cost  -0.00183117\n",
      "Pre-training layer 0, epoch 406, cost  -0.00480451\n",
      "Pre-training layer 0, epoch 407, cost  -0.00270311\n",
      "Pre-training layer 0, epoch 408, cost  -0.00330828\n",
      "Pre-training layer 0, epoch 409, cost  -0.00368415\n",
      "Pre-training layer 0, epoch 410, cost  -0.00190788\n",
      "Pre-training layer 0, epoch 411, cost  -0.0031482\n",
      "Pre-training layer 0, epoch 412, cost  -0.00316342\n",
      "Pre-training layer 0, epoch 413, cost  -0.00479092\n",
      "Pre-training layer 0, epoch 414, cost  -0.00318461\n",
      "Pre-training layer 0, epoch 415, cost  -0.00287155\n",
      "Pre-training layer 0, epoch 416, cost  -0.0017595\n",
      "Pre-training layer 0, epoch 417, cost  -0.00243126\n",
      "Pre-training layer 0, epoch 418, cost  -0.00136919\n",
      "Pre-training layer 0, epoch 419, cost  -0.00394493\n",
      "Pre-training layer 0, epoch 420, cost  -0.00254909\n",
      "Pre-training layer 0, epoch 421, cost  -0.00188261\n",
      "Pre-training layer 0, epoch 422, cost  -0.00336108\n",
      "Pre-training layer 0, epoch 423, cost  -0.00379078\n",
      "Pre-training layer 0, epoch 424, cost  -0.00432149\n",
      "Pre-training layer 0, epoch 425, cost  -0.000925911\n",
      "Pre-training layer 0, epoch 426, cost  -5.15464e-05\n",
      "Pre-training layer 0, epoch 427, cost  -0.0012503\n",
      "Pre-training layer 0, epoch 428, cost  0.000245907\n",
      "Pre-training layer 0, epoch 429, cost  -0.00282849\n",
      "Pre-training layer 0, epoch 430, cost  -0.00310835\n",
      "Pre-training layer 0, epoch 431, cost  -0.001691\n",
      "Pre-training layer 0, epoch 432, cost  -0.00293188\n",
      "Pre-training layer 0, epoch 433, cost  -0.00170802\n",
      "Pre-training layer 0, epoch 434, cost  -0.00363927\n",
      "Pre-training layer 0, epoch 435, cost  -0.00413524\n",
      "Pre-training layer 0, epoch 436, cost  -0.00160179\n",
      "Pre-training layer 0, epoch 437, cost  -0.00180174\n",
      "Pre-training layer 0, epoch 438, cost  -0.00300607\n",
      "Pre-training layer 0, epoch 439, cost  -0.000791934\n",
      "Pre-training layer 0, epoch 440, cost  -0.00154904\n",
      "Pre-training layer 0, epoch 441, cost  -0.00181491\n",
      "Pre-training layer 0, epoch 442, cost  -0.00161333\n",
      "Pre-training layer 0, epoch 443, cost  -0.00312557\n",
      "Pre-training layer 0, epoch 444, cost  -0.0020163\n",
      "Pre-training layer 0, epoch 445, cost  -0.0024578\n",
      "Pre-training layer 0, epoch 446, cost  -0.0013936\n",
      "Pre-training layer 0, epoch 447, cost  -0.000445285\n",
      "Pre-training layer 0, epoch 448, cost  -0.00264532\n",
      "Pre-training layer 0, epoch 449, cost  -0.00185622\n",
      "Pre-training layer 0, epoch 450, cost  -0.00303822\n",
      "Pre-training layer 0, epoch 451, cost  -0.0028766\n",
      "Pre-training layer 0, epoch 452, cost  -0.00212435\n",
      "Pre-training layer 0, epoch 453, cost  -0.00281213\n",
      "Pre-training layer 0, epoch 454, cost  -0.00306556\n",
      "Pre-training layer 0, epoch 455, cost  -0.00101897\n",
      "Pre-training layer 0, epoch 456, cost  -0.00287071\n",
      "Pre-training layer 0, epoch 457, cost  -0.00295434\n",
      "Pre-training layer 0, epoch 458, cost  -0.00179059\n",
      "Pre-training layer 0, epoch 459, cost  -0.00179242\n",
      "Pre-training layer 0, epoch 460, cost  -0.00320651\n",
      "Pre-training layer 0, epoch 461, cost  -0.00202336\n",
      "Pre-training layer 0, epoch 462, cost  -0.00337439\n",
      "Pre-training layer 0, epoch 463, cost  -0.00268547\n",
      "Pre-training layer 0, epoch 464, cost  -0.00163247\n",
      "Pre-training layer 0, epoch 465, cost  -0.00164841\n",
      "Pre-training layer 0, epoch 466, cost  -0.00250628\n",
      "Pre-training layer 0, epoch 467, cost  -0.00301114\n",
      "Pre-training layer 0, epoch 468, cost  -0.00153852\n",
      "Pre-training layer 0, epoch 469, cost  -0.00345886\n",
      "Pre-training layer 0, epoch 470, cost  -0.00458087\n",
      "Pre-training layer 0, epoch 471, cost  -0.00233469\n",
      "Pre-training layer 0, epoch 472, cost  -0.0021148\n",
      "Pre-training layer 0, epoch 473, cost  -0.00563183\n",
      "Pre-training layer 0, epoch 474, cost  -0.001897\n",
      "Pre-training layer 0, epoch 475, cost  -0.00239134\n",
      "Pre-training layer 0, epoch 476, cost  -0.00322377\n",
      "Pre-training layer 0, epoch 477, cost  -0.00238186\n",
      "Pre-training layer 0, epoch 478, cost  -0.00258208\n",
      "Pre-training layer 0, epoch 479, cost  -0.00139552\n",
      "Pre-training layer 0, epoch 480, cost  -0.00149675\n",
      "Pre-training layer 0, epoch 481, cost  -0.00162119\n",
      "Pre-training layer 0, epoch 482, cost  -0.00516538\n",
      "Pre-training layer 0, epoch 483, cost  -0.00124728\n",
      "Pre-training layer 0, epoch 484, cost  -0.00349608\n",
      "Pre-training layer 0, epoch 485, cost  -0.0023038\n",
      "Pre-training layer 0, epoch 486, cost  -0.00336463\n",
      "Pre-training layer 0, epoch 487, cost  -0.00238994\n",
      "Pre-training layer 0, epoch 488, cost  -0.00403523\n",
      "Pre-training layer 0, epoch 489, cost  -0.00341792\n",
      "Pre-training layer 0, epoch 490, cost  -0.00486075\n",
      "Pre-training layer 0, epoch 491, cost  -0.00332349\n",
      "Pre-training layer 0, epoch 492, cost  -0.00227153\n",
      "Pre-training layer 0, epoch 493, cost  -0.00303371\n",
      "Pre-training layer 0, epoch 494, cost  -0.00324713\n",
      "Pre-training layer 0, epoch 495, cost  -0.002134\n",
      "Pre-training layer 0, epoch 496, cost  -0.00497362\n",
      "Pre-training layer 0, epoch 497, cost  -0.00399812\n",
      "Pre-training layer 0, epoch 498, cost  -0.00123999\n",
      "Pre-training layer 0, epoch 499, cost  -0.00274448\n",
      "Pre-training layer 1, epoch 0, cost  -3561.84\n",
      "Pre-training layer 1, epoch 1, cost  -3516.99\n",
      "Pre-training layer 1, epoch 2, cost  -3504.09\n",
      "Pre-training layer 1, epoch 3, cost  -3496.34\n",
      "Pre-training layer 1, epoch 4, cost  -3491.24\n",
      "Pre-training layer 1, epoch 5, cost  -3487.97\n",
      "Pre-training layer 1, epoch 6, cost  -3485.62\n",
      "Pre-training layer 1, epoch 7, cost  -3483.92\n",
      "Pre-training layer 1, epoch 8, cost  -3482.65\n",
      "Pre-training layer 1, epoch 9, cost  -3481.72\n",
      "Pre-training layer 1, epoch 10, cost  -3481.08\n",
      "Pre-training layer 1, epoch 11, cost  -3480.53\n",
      "Pre-training layer 1, epoch 12, cost  -3480.08\n",
      "Pre-training layer 1, epoch 13, cost  -3479.73\n",
      "Pre-training layer 1, epoch 14, cost  -3479.41\n",
      "Pre-training layer 1, epoch 15, cost  -3479.08\n",
      "Pre-training layer 1, epoch 16, cost  -3478.99\n",
      "Pre-training layer 1, epoch 17, cost  -3478.74\n",
      "Pre-training layer 1, epoch 18, cost  -3478.63\n",
      "Pre-training layer 1, epoch 19, cost  -3478.48\n",
      "Pre-training layer 1, epoch 20, cost  -3478.42\n",
      "Pre-training layer 1, epoch 21, cost  -3478.25\n",
      "Pre-training layer 1, epoch 22, cost  -3478.17\n",
      "Pre-training layer 1, epoch 23, cost  -3478.08\n",
      "Pre-training layer 1, epoch 24, cost  -3477.93\n",
      "Pre-training layer 1, epoch 25, cost  -3477.95\n",
      "Pre-training layer 1, epoch 26, cost  -3477.85\n",
      "Pre-training layer 1, epoch 27, cost  -3477.83\n",
      "Pre-training layer 1, epoch 28, cost  -3477.76\n",
      "Pre-training layer 1, epoch 29, cost  -3477.72\n",
      "Pre-training layer 1, epoch 30, cost  -3477.65\n",
      "Pre-training layer 1, epoch 31, cost  -3477.61\n",
      "Pre-training layer 1, epoch 32, cost  -3477.52\n",
      "Pre-training layer 1, epoch 33, cost  -3477.54\n",
      "Pre-training layer 1, epoch 34, cost  -3477.52\n",
      "Pre-training layer 1, epoch 35, cost  -3477.47\n",
      "Pre-training layer 1, epoch 36, cost  -3477.47\n",
      "Pre-training layer 1, epoch 37, cost  -3477.49\n",
      "Pre-training layer 1, epoch 38, cost  -3477.43\n",
      "Pre-training layer 1, epoch 39, cost  -3477.4\n",
      "Pre-training layer 1, epoch 40, cost  -3477.4\n",
      "Pre-training layer 1, epoch 41, cost  -3477.39\n",
      "Pre-training layer 1, epoch 42, cost  -3477.38\n",
      "Pre-training layer 1, epoch 43, cost  -3477.33\n",
      "Pre-training layer 1, epoch 44, cost  -3477.35\n",
      "Pre-training layer 1, epoch 45, cost  -3477.28\n",
      "Pre-training layer 1, epoch 46, cost  -3477.27\n",
      "Pre-training layer 1, epoch 47, cost  -3477.28\n",
      "Pre-training layer 1, epoch 48, cost  -3477.29\n",
      "Pre-training layer 1, epoch 49, cost  -3477.26\n",
      "Pre-training layer 1, epoch 50, cost  -3477.27\n",
      "Pre-training layer 1, epoch 51, cost  -3477.18\n",
      "Pre-training layer 1, epoch 52, cost  -3477.24\n",
      "Pre-training layer 1, epoch 53, cost  -3477.21\n",
      "Pre-training layer 1, epoch 54, cost  -3477.22\n",
      "Pre-training layer 1, epoch 55, cost  -3477.18\n",
      "Pre-training layer 1, epoch 56, cost  -3477.17\n",
      "Pre-training layer 1, epoch 57, cost  -3477.16\n",
      "Pre-training layer 1, epoch 58, cost  -3477.18\n",
      "Pre-training layer 1, epoch 59, cost  -3477.15\n",
      "Pre-training layer 1, epoch 60, cost  -3477.14\n",
      "Pre-training layer 1, epoch 61, cost  -3477.17\n",
      "Pre-training layer 1, epoch 62, cost  -3477.14\n",
      "Pre-training layer 1, epoch 63, cost  -3477.14\n",
      "Pre-training layer 1, epoch 64, cost  -3477.08\n",
      "Pre-training layer 1, epoch 65, cost  -3477.11\n",
      "Pre-training layer 1, epoch 66, cost  -3477.11\n",
      "Pre-training layer 1, epoch 67, cost  -3477.12\n",
      "Pre-training layer 1, epoch 68, cost  -3477.11\n",
      "Pre-training layer 1, epoch 69, cost  -3477.09\n",
      "Pre-training layer 1, epoch 70, cost  -3477.1\n",
      "Pre-training layer 1, epoch 71, cost  -3477.06\n",
      "Pre-training layer 1, epoch 72, cost  -3477.05\n",
      "Pre-training layer 1, epoch 73, cost  -3477.03\n",
      "Pre-training layer 1, epoch 74, cost  -3477.09\n",
      "Pre-training layer 1, epoch 75, cost  -3477.06\n",
      "Pre-training layer 1, epoch 76, cost  -3477.06\n",
      "Pre-training layer 1, epoch 77, cost  -3477.01\n",
      "Pre-training layer 1, epoch 78, cost  -3477.07\n",
      "Pre-training layer 1, epoch 79, cost  -3477.05\n",
      "Pre-training layer 1, epoch 80, cost  -3477.06\n",
      "Pre-training layer 1, epoch 81, cost  -3477.04\n",
      "Pre-training layer 1, epoch 82, cost  -3476.99\n",
      "Pre-training layer 1, epoch 83, cost  -3477.02\n",
      "Pre-training layer 1, epoch 84, cost  -3477.04\n",
      "Pre-training layer 1, epoch 85, cost  -3477.0\n",
      "Pre-training layer 1, epoch 86, cost  -3476.99\n",
      "Pre-training layer 1, epoch 87, cost  -3477.08\n",
      "Pre-training layer 1, epoch 88, cost  -3477.05\n",
      "Pre-training layer 1, epoch 89, cost  -3477.0\n",
      "Pre-training layer 1, epoch 90, cost  -3477.02\n",
      "Pre-training layer 1, epoch 91, cost  -3476.99\n",
      "Pre-training layer 1, epoch 92, cost  -3477.0\n",
      "Pre-training layer 1, epoch 93, cost  -3477.03\n",
      "Pre-training layer 1, epoch 94, cost  -3476.99\n",
      "Pre-training layer 1, epoch 95, cost  -3477.0\n",
      "Pre-training layer 1, epoch 96, cost  -3476.97\n",
      "Pre-training layer 1, epoch 97, cost  -3476.96\n",
      "Pre-training layer 1, epoch 98, cost  -3477.0\n",
      "Pre-training layer 1, epoch 99, cost  -3477.0\n",
      "Pre-training layer 1, epoch 100, cost  -3476.95\n",
      "Pre-training layer 1, epoch 101, cost  -3477.0\n",
      "Pre-training layer 1, epoch 102, cost  -3476.96\n",
      "Pre-training layer 1, epoch 103, cost  -3476.96\n",
      "Pre-training layer 1, epoch 104, cost  -3476.94\n",
      "Pre-training layer 1, epoch 105, cost  -3476.97\n",
      "Pre-training layer 1, epoch 106, cost  -3476.95\n",
      "Pre-training layer 1, epoch 107, cost  -3476.95\n",
      "Pre-training layer 1, epoch 108, cost  -3476.97\n",
      "Pre-training layer 1, epoch 109, cost  -3476.92\n",
      "Pre-training layer 1, epoch 110, cost  -3476.99\n",
      "Pre-training layer 1, epoch 111, cost  -3476.97\n",
      "Pre-training layer 1, epoch 112, cost  -3476.99\n",
      "Pre-training layer 1, epoch 113, cost  -3476.93\n",
      "Pre-training layer 1, epoch 114, cost  -3476.93\n",
      "Pre-training layer 1, epoch 115, cost  -3476.96\n",
      "Pre-training layer 1, epoch 116, cost  -3477.01\n",
      "Pre-training layer 1, epoch 117, cost  -3476.96\n",
      "Pre-training layer 1, epoch 118, cost  -3476.94\n",
      "Pre-training layer 1, epoch 119, cost  -3476.94\n",
      "Pre-training layer 1, epoch 120, cost  -3476.92\n",
      "Pre-training layer 1, epoch 121, cost  -3476.9\n",
      "Pre-training layer 1, epoch 122, cost  -3476.89\n",
      "Pre-training layer 1, epoch 123, cost  -3476.92\n",
      "Pre-training layer 1, epoch 124, cost  -3476.94\n",
      "Pre-training layer 1, epoch 125, cost  -3476.94\n",
      "Pre-training layer 1, epoch 126, cost  -3476.94\n",
      "Pre-training layer 1, epoch 127, cost  -3476.89\n",
      "Pre-training layer 1, epoch 128, cost  -3476.95\n",
      "Pre-training layer 1, epoch 129, cost  -3476.91\n",
      "Pre-training layer 1, epoch 130, cost  -3476.98\n",
      "Pre-training layer 1, epoch 131, cost  -3476.94\n",
      "Pre-training layer 1, epoch 132, cost  -3476.9\n",
      "Pre-training layer 1, epoch 133, cost  -3476.89\n",
      "Pre-training layer 1, epoch 134, cost  -3476.93\n",
      "Pre-training layer 1, epoch 135, cost  -3476.91\n",
      "Pre-training layer 1, epoch 136, cost  -3476.89\n",
      "Pre-training layer 1, epoch 137, cost  -3476.92\n",
      "Pre-training layer 1, epoch 138, cost  -3476.94\n",
      "Pre-training layer 1, epoch 139, cost  -3476.94\n",
      "Pre-training layer 1, epoch 140, cost  -3476.94\n",
      "Pre-training layer 1, epoch 141, cost  -3476.93\n",
      "Pre-training layer 1, epoch 142, cost  -3476.93\n",
      "Pre-training layer 1, epoch 143, cost  -3476.92\n",
      "Pre-training layer 1, epoch 144, cost  -3476.95\n",
      "Pre-training layer 1, epoch 145, cost  -3476.95\n",
      "Pre-training layer 1, epoch 146, cost  -3476.92\n",
      "Pre-training layer 1, epoch 147, cost  -3476.85\n",
      "Pre-training layer 1, epoch 148, cost  -3476.92\n",
      "Pre-training layer 1, epoch 149, cost  -3476.93\n",
      "Pre-training layer 1, epoch 150, cost  -3476.88\n",
      "Pre-training layer 1, epoch 151, cost  -3476.88\n",
      "Pre-training layer 1, epoch 152, cost  -3476.87\n",
      "Pre-training layer 1, epoch 153, cost  -3476.87\n",
      "Pre-training layer 1, epoch 154, cost  -3476.87\n",
      "Pre-training layer 1, epoch 155, cost  -3476.96\n",
      "Pre-training layer 1, epoch 156, cost  -3476.9\n",
      "Pre-training layer 1, epoch 157, cost  -3476.91\n",
      "Pre-training layer 1, epoch 158, cost  -3476.88\n",
      "Pre-training layer 1, epoch 159, cost  -3476.86\n",
      "Pre-training layer 1, epoch 160, cost  -3476.91\n",
      "Pre-training layer 1, epoch 161, cost  -3476.87\n",
      "Pre-training layer 1, epoch 162, cost  -3476.87\n",
      "Pre-training layer 1, epoch 163, cost  -3476.94\n",
      "Pre-training layer 1, epoch 164, cost  -3476.83\n",
      "Pre-training layer 1, epoch 165, cost  -3476.93\n",
      "Pre-training layer 1, epoch 166, cost  -3476.92\n",
      "Pre-training layer 1, epoch 167, cost  -3476.94\n",
      "Pre-training layer 1, epoch 168, cost  -3476.89\n",
      "Pre-training layer 1, epoch 169, cost  -3476.89\n",
      "Pre-training layer 1, epoch 170, cost  -3476.85\n",
      "Pre-training layer 1, epoch 171, cost  -3476.87\n",
      "Pre-training layer 1, epoch 172, cost  -3476.87\n",
      "Pre-training layer 1, epoch 173, cost  -3476.86\n",
      "Pre-training layer 1, epoch 174, cost  -3476.82\n",
      "Pre-training layer 1, epoch 175, cost  -3476.9\n",
      "Pre-training layer 1, epoch 176, cost  -3476.89\n",
      "Pre-training layer 1, epoch 177, cost  -3476.93\n",
      "Pre-training layer 1, epoch 178, cost  -3476.85\n",
      "Pre-training layer 1, epoch 179, cost  -3476.85\n",
      "Pre-training layer 1, epoch 180, cost  -3476.88\n",
      "Pre-training layer 1, epoch 181, cost  -3476.89\n",
      "Pre-training layer 1, epoch 182, cost  -3476.9\n",
      "Pre-training layer 1, epoch 183, cost  -3476.87\n",
      "Pre-training layer 1, epoch 184, cost  -3476.93\n",
      "Pre-training layer 1, epoch 185, cost  -3476.88\n",
      "Pre-training layer 1, epoch 186, cost  -3476.85\n",
      "Pre-training layer 1, epoch 187, cost  -3476.91\n",
      "Pre-training layer 1, epoch 188, cost  -3476.86\n",
      "Pre-training layer 1, epoch 189, cost  -3476.84\n",
      "Pre-training layer 1, epoch 190, cost  -3476.84\n",
      "Pre-training layer 1, epoch 191, cost  -3476.92\n",
      "Pre-training layer 1, epoch 192, cost  -3476.87\n",
      "Pre-training layer 1, epoch 193, cost  -3476.86\n",
      "Pre-training layer 1, epoch 194, cost  -3476.87\n",
      "Pre-training layer 1, epoch 195, cost  -3476.85\n",
      "Pre-training layer 1, epoch 196, cost  -3476.91\n",
      "Pre-training layer 1, epoch 197, cost  -3476.84\n",
      "Pre-training layer 1, epoch 198, cost  -3476.84\n",
      "Pre-training layer 1, epoch 199, cost  -3476.88\n",
      "Pre-training layer 1, epoch 200, cost  -3476.9\n",
      "Pre-training layer 1, epoch 201, cost  -3476.88\n",
      "Pre-training layer 1, epoch 202, cost  -3476.86\n",
      "Pre-training layer 1, epoch 203, cost  -3476.84\n",
      "Pre-training layer 1, epoch 204, cost  -3476.89\n",
      "Pre-training layer 1, epoch 205, cost  -3476.9\n",
      "Pre-training layer 1, epoch 206, cost  -3476.86\n",
      "Pre-training layer 1, epoch 207, cost  -3476.84\n",
      "Pre-training layer 1, epoch 208, cost  -3476.87\n",
      "Pre-training layer 1, epoch 209, cost  -3476.89\n",
      "Pre-training layer 1, epoch 210, cost  -3476.83\n",
      "Pre-training layer 1, epoch 211, cost  -3476.88\n",
      "Pre-training layer 1, epoch 212, cost  -3476.89\n",
      "Pre-training layer 1, epoch 213, cost  -3476.86\n",
      "Pre-training layer 1, epoch 214, cost  -3476.84\n",
      "Pre-training layer 1, epoch 215, cost  -3476.89\n",
      "Pre-training layer 1, epoch 216, cost  -3476.85\n",
      "Pre-training layer 1, epoch 217, cost  -3476.85\n",
      "Pre-training layer 1, epoch 218, cost  -3476.9\n",
      "Pre-training layer 1, epoch 219, cost  -3476.85\n",
      "Pre-training layer 1, epoch 220, cost  -3476.86\n",
      "Pre-training layer 1, epoch 221, cost  -3476.86\n",
      "Pre-training layer 1, epoch 222, cost  -3476.84\n",
      "Pre-training layer 1, epoch 223, cost  -3476.83\n",
      "Pre-training layer 1, epoch 224, cost  -3476.88\n",
      "Pre-training layer 1, epoch 225, cost  -3476.85\n",
      "Pre-training layer 1, epoch 226, cost  -3476.82\n",
      "Pre-training layer 1, epoch 227, cost  -3476.85\n",
      "Pre-training layer 1, epoch 228, cost  -3476.83\n",
      "Pre-training layer 1, epoch 229, cost  -3476.87\n",
      "Pre-training layer 1, epoch 230, cost  -3476.85\n",
      "Pre-training layer 1, epoch 231, cost  -3476.82\n",
      "Pre-training layer 1, epoch 232, cost  -3476.89\n",
      "Pre-training layer 1, epoch 233, cost  -3476.86\n",
      "Pre-training layer 1, epoch 234, cost  -3476.85\n",
      "Pre-training layer 1, epoch 235, cost  -3476.82\n",
      "Pre-training layer 1, epoch 236, cost  -3476.84\n",
      "Pre-training layer 1, epoch 237, cost  -3476.85\n",
      "Pre-training layer 1, epoch 238, cost  -3476.86\n",
      "Pre-training layer 1, epoch 239, cost  -3476.91\n",
      "Pre-training layer 1, epoch 240, cost  -3476.84\n",
      "Pre-training layer 1, epoch 241, cost  -3476.89\n",
      "Pre-training layer 1, epoch 242, cost  -3476.84\n",
      "Pre-training layer 1, epoch 243, cost  -3476.87\n",
      "Pre-training layer 1, epoch 244, cost  -3476.87\n",
      "Pre-training layer 1, epoch 245, cost  -3476.86\n",
      "Pre-training layer 1, epoch 246, cost  -3476.81\n",
      "Pre-training layer 1, epoch 247, cost  -3476.82\n",
      "Pre-training layer 1, epoch 248, cost  -3476.88\n",
      "Pre-training layer 1, epoch 249, cost  -3476.82\n",
      "Pre-training layer 1, epoch 250, cost  -3476.92\n",
      "Pre-training layer 1, epoch 251, cost  -3476.83\n",
      "Pre-training layer 1, epoch 252, cost  -3476.83\n",
      "Pre-training layer 1, epoch 253, cost  -3476.8\n",
      "Pre-training layer 1, epoch 254, cost  -3476.9\n",
      "Pre-training layer 1, epoch 255, cost  -3476.82\n",
      "Pre-training layer 1, epoch 256, cost  -3476.85\n",
      "Pre-training layer 1, epoch 257, cost  -3476.91\n",
      "Pre-training layer 1, epoch 258, cost  -3476.84\n",
      "Pre-training layer 1, epoch 259, cost  -3476.82\n",
      "Pre-training layer 1, epoch 260, cost  -3476.83\n",
      "Pre-training layer 1, epoch 261, cost  -3476.9\n",
      "Pre-training layer 1, epoch 262, cost  -3476.83\n",
      "Pre-training layer 1, epoch 263, cost  -3476.81\n",
      "Pre-training layer 1, epoch 264, cost  -3476.83\n",
      "Pre-training layer 1, epoch 265, cost  -3476.88\n",
      "Pre-training layer 1, epoch 266, cost  -3476.86\n",
      "Pre-training layer 1, epoch 267, cost  -3476.81\n",
      "Pre-training layer 1, epoch 268, cost  -3476.85\n",
      "Pre-training layer 1, epoch 269, cost  -3476.83\n",
      "Pre-training layer 1, epoch 270, cost  -3476.84\n",
      "Pre-training layer 1, epoch 271, cost  -3476.83\n",
      "Pre-training layer 1, epoch 272, cost  -3476.86\n",
      "Pre-training layer 1, epoch 273, cost  -3476.83\n",
      "Pre-training layer 1, epoch 274, cost  -3476.8\n",
      "Pre-training layer 1, epoch 275, cost  -3476.83\n",
      "Pre-training layer 1, epoch 276, cost  -3476.79\n",
      "Pre-training layer 1, epoch 277, cost  -3476.8\n",
      "Pre-training layer 1, epoch 278, cost  -3476.82\n",
      "Pre-training layer 1, epoch 279, cost  -3476.85\n",
      "Pre-training layer 1, epoch 280, cost  -3476.84\n",
      "Pre-training layer 1, epoch 281, cost  -3476.84\n",
      "Pre-training layer 1, epoch 282, cost  -3476.82\n",
      "Pre-training layer 1, epoch 283, cost  -3476.82\n",
      "Pre-training layer 1, epoch 284, cost  -3476.83\n",
      "Pre-training layer 1, epoch 285, cost  -3476.83\n",
      "Pre-training layer 1, epoch 286, cost  -3476.81\n",
      "Pre-training layer 1, epoch 287, cost  -3476.85\n",
      "Pre-training layer 1, epoch 288, cost  -3476.87\n",
      "Pre-training layer 1, epoch 289, cost  -3476.85\n",
      "Pre-training layer 1, epoch 290, cost  -3476.81\n",
      "Pre-training layer 1, epoch 291, cost  -3476.83\n",
      "Pre-training layer 1, epoch 292, cost  -3476.85\n",
      "Pre-training layer 1, epoch 293, cost  -3476.81\n",
      "Pre-training layer 1, epoch 294, cost  -3476.85\n",
      "Pre-training layer 1, epoch 295, cost  -3476.8\n",
      "Pre-training layer 1, epoch 296, cost  -3476.87\n",
      "Pre-training layer 1, epoch 297, cost  -3476.8\n",
      "Pre-training layer 1, epoch 298, cost  -3476.83\n",
      "Pre-training layer 1, epoch 299, cost  -3476.77\n",
      "Pre-training layer 1, epoch 300, cost  -3476.82\n",
      "Pre-training layer 1, epoch 301, cost  -3476.85\n",
      "Pre-training layer 1, epoch 302, cost  -3476.78\n",
      "Pre-training layer 1, epoch 303, cost  -3476.85\n",
      "Pre-training layer 1, epoch 304, cost  -3476.83\n",
      "Pre-training layer 1, epoch 305, cost  -3476.85\n",
      "Pre-training layer 1, epoch 306, cost  -3476.84\n",
      "Pre-training layer 1, epoch 307, cost  -3476.84\n",
      "Pre-training layer 1, epoch 308, cost  -3476.81\n",
      "Pre-training layer 1, epoch 309, cost  -3476.9\n",
      "Pre-training layer 1, epoch 310, cost  -3476.83\n",
      "Pre-training layer 1, epoch 311, cost  -3476.8\n",
      "Pre-training layer 1, epoch 312, cost  -3476.86\n",
      "Pre-training layer 1, epoch 313, cost  -3476.81\n",
      "Pre-training layer 1, epoch 314, cost  -3476.79\n",
      "Pre-training layer 1, epoch 315, cost  -3476.84\n",
      "Pre-training layer 1, epoch 316, cost  -3476.81\n",
      "Pre-training layer 1, epoch 317, cost  -3476.84\n",
      "Pre-training layer 1, epoch 318, cost  -3476.83\n",
      "Pre-training layer 1, epoch 319, cost  -3476.81\n",
      "Pre-training layer 1, epoch 320, cost  -3476.83\n",
      "Pre-training layer 1, epoch 321, cost  -3476.83\n",
      "Pre-training layer 1, epoch 322, cost  -3476.87\n",
      "Pre-training layer 1, epoch 323, cost  -3476.79\n",
      "Pre-training layer 1, epoch 324, cost  -3476.82\n",
      "Pre-training layer 1, epoch 325, cost  -3476.86\n",
      "Pre-training layer 1, epoch 326, cost  -3476.8\n",
      "Pre-training layer 1, epoch 327, cost  -3476.84\n",
      "Pre-training layer 1, epoch 328, cost  -3476.83\n",
      "Pre-training layer 1, epoch 329, cost  -3476.82\n",
      "Pre-training layer 1, epoch 330, cost  -3476.81\n",
      "Pre-training layer 1, epoch 331, cost  -3476.82\n",
      "Pre-training layer 1, epoch 332, cost  -3476.81\n",
      "Pre-training layer 1, epoch 333, cost  -3476.85\n",
      "Pre-training layer 1, epoch 334, cost  -3476.83\n",
      "Pre-training layer 1, epoch 335, cost  -3476.87\n",
      "Pre-training layer 1, epoch 336, cost  -3476.79\n",
      "Pre-training layer 1, epoch 337, cost  -3476.82\n",
      "Pre-training layer 1, epoch 338, cost  -3476.86\n",
      "Pre-training layer 1, epoch 339, cost  -3476.79\n",
      "Pre-training layer 1, epoch 340, cost  -3476.85\n",
      "Pre-training layer 1, epoch 341, cost  -3476.81\n",
      "Pre-training layer 1, epoch 342, cost  -3476.81\n",
      "Pre-training layer 1, epoch 343, cost  -3476.82\n",
      "Pre-training layer 1, epoch 344, cost  -3476.82\n",
      "Pre-training layer 1, epoch 345, cost  -3476.82\n",
      "Pre-training layer 1, epoch 346, cost  -3476.83\n",
      "Pre-training layer 1, epoch 347, cost  -3476.85\n",
      "Pre-training layer 1, epoch 348, cost  -3476.79\n",
      "Pre-training layer 1, epoch 349, cost  -3476.86\n",
      "Pre-training layer 1, epoch 350, cost  -3476.87\n",
      "Pre-training layer 1, epoch 351, cost  -3476.78\n",
      "Pre-training layer 1, epoch 352, cost  -3476.83\n",
      "Pre-training layer 1, epoch 353, cost  -3476.85\n",
      "Pre-training layer 1, epoch 354, cost  -3476.82\n",
      "Pre-training layer 1, epoch 355, cost  -3476.83\n",
      "Pre-training layer 1, epoch 356, cost  -3476.83\n",
      "Pre-training layer 1, epoch 357, cost  -3476.79\n",
      "Pre-training layer 1, epoch 358, cost  -3476.8\n",
      "Pre-training layer 1, epoch 359, cost  -3476.81\n",
      "Pre-training layer 1, epoch 360, cost  -3476.85\n",
      "Pre-training layer 1, epoch 361, cost  -3476.78\n",
      "Pre-training layer 1, epoch 362, cost  -3476.81\n",
      "Pre-training layer 1, epoch 363, cost  -3476.78\n",
      "Pre-training layer 1, epoch 364, cost  -3476.82\n",
      "Pre-training layer 1, epoch 365, cost  -3476.84\n",
      "Pre-training layer 1, epoch 366, cost  -3476.83\n",
      "Pre-training layer 1, epoch 367, cost  -3476.83\n",
      "Pre-training layer 1, epoch 368, cost  -3476.83\n",
      "Pre-training layer 1, epoch 369, cost  -3476.84\n",
      "Pre-training layer 1, epoch 370, cost  -3476.82\n",
      "Pre-training layer 1, epoch 371, cost  -3476.83\n",
      "Pre-training layer 1, epoch 372, cost  -3476.8\n",
      "Pre-training layer 1, epoch 373, cost  -3476.83\n",
      "Pre-training layer 1, epoch 374, cost  -3476.84\n",
      "Pre-training layer 1, epoch 375, cost  -3476.86\n",
      "Pre-training layer 1, epoch 376, cost  -3476.79\n",
      "Pre-training layer 1, epoch 377, cost  -3476.82\n",
      "Pre-training layer 1, epoch 378, cost  -3476.82\n",
      "Pre-training layer 1, epoch 379, cost  -3476.83\n",
      "Pre-training layer 1, epoch 380, cost  -3476.79\n",
      "Pre-training layer 1, epoch 381, cost  -3476.81\n",
      "Pre-training layer 1, epoch 382, cost  -3476.79\n",
      "Pre-training layer 1, epoch 383, cost  -3476.84\n",
      "Pre-training layer 1, epoch 384, cost  -3476.8\n",
      "Pre-training layer 1, epoch 385, cost  -3476.86\n",
      "Pre-training layer 1, epoch 386, cost  -3476.79\n",
      "Pre-training layer 1, epoch 387, cost  -3476.81\n",
      "Pre-training layer 1, epoch 388, cost  -3476.85\n",
      "Pre-training layer 1, epoch 389, cost  -3476.79\n",
      "Pre-training layer 1, epoch 390, cost  -3476.85\n",
      "Pre-training layer 1, epoch 391, cost  -3476.81\n",
      "Pre-training layer 1, epoch 392, cost  -3476.81\n",
      "Pre-training layer 1, epoch 393, cost  -3476.8\n",
      "Pre-training layer 1, epoch 394, cost  -3476.85\n",
      "Pre-training layer 1, epoch 395, cost  -3476.81\n",
      "Pre-training layer 1, epoch 396, cost  -3476.81\n",
      "Pre-training layer 1, epoch 397, cost  -3476.78\n",
      "Pre-training layer 1, epoch 398, cost  -3476.8\n",
      "Pre-training layer 1, epoch 399, cost  -3476.79\n",
      "Pre-training layer 1, epoch 400, cost  -3476.84\n",
      "Pre-training layer 1, epoch 401, cost  -3476.82\n",
      "Pre-training layer 1, epoch 402, cost  -3476.79\n",
      "Pre-training layer 1, epoch 403, cost  -3476.83\n",
      "Pre-training layer 1, epoch 404, cost  -3476.8\n",
      "Pre-training layer 1, epoch 405, cost  -3476.83\n",
      "Pre-training layer 1, epoch 406, cost  -3476.82\n",
      "Pre-training layer 1, epoch 407, cost  -3476.77\n",
      "Pre-training layer 1, epoch 408, cost  -3476.79\n",
      "Pre-training layer 1, epoch 409, cost  -3476.84\n",
      "Pre-training layer 1, epoch 410, cost  -3476.77\n",
      "Pre-training layer 1, epoch 411, cost  -3476.77\n",
      "Pre-training layer 1, epoch 412, cost  -3476.8\n",
      "Pre-training layer 1, epoch 413, cost  -3476.82\n",
      "Pre-training layer 1, epoch 414, cost  -3476.85\n",
      "Pre-training layer 1, epoch 415, cost  -3476.81\n",
      "Pre-training layer 1, epoch 416, cost  -3476.79\n",
      "Pre-training layer 1, epoch 417, cost  -3476.82\n",
      "Pre-training layer 1, epoch 418, cost  -3476.78\n",
      "Pre-training layer 1, epoch 419, cost  -3476.78\n",
      "Pre-training layer 1, epoch 420, cost  -3476.82\n",
      "Pre-training layer 1, epoch 421, cost  -3476.8\n",
      "Pre-training layer 1, epoch 422, cost  -3476.8\n",
      "Pre-training layer 1, epoch 423, cost  -3476.77\n",
      "Pre-training layer 1, epoch 424, cost  -3476.77\n",
      "Pre-training layer 1, epoch 425, cost  -3476.79\n",
      "Pre-training layer 1, epoch 426, cost  -3476.82\n",
      "Pre-training layer 1, epoch 427, cost  -3476.87\n",
      "Pre-training layer 1, epoch 428, cost  -3476.79\n",
      "Pre-training layer 1, epoch 429, cost  -3476.8\n",
      "Pre-training layer 1, epoch 430, cost  -3476.82\n",
      "Pre-training layer 1, epoch 431, cost  -3476.82\n",
      "Pre-training layer 1, epoch 432, cost  -3476.85\n",
      "Pre-training layer 1, epoch 433, cost  -3476.83\n",
      "Pre-training layer 1, epoch 434, cost  -3476.84\n",
      "Pre-training layer 1, epoch 435, cost  -3476.81\n",
      "Pre-training layer 1, epoch 436, cost  -3476.83\n",
      "Pre-training layer 1, epoch 437, cost  -3476.83\n",
      "Pre-training layer 1, epoch 438, cost  -3476.85\n",
      "Pre-training layer 1, epoch 439, cost  -3476.82\n",
      "Pre-training layer 1, epoch 440, cost  -3476.88\n",
      "Pre-training layer 1, epoch 441, cost  -3476.81\n",
      "Pre-training layer 1, epoch 442, cost  -3476.87\n",
      "Pre-training layer 1, epoch 443, cost  -3476.8\n",
      "Pre-training layer 1, epoch 444, cost  -3476.79\n",
      "Pre-training layer 1, epoch 445, cost  -3476.81\n",
      "Pre-training layer 1, epoch 446, cost  -3476.78\n",
      "Pre-training layer 1, epoch 447, cost  -3476.79\n",
      "Pre-training layer 1, epoch 448, cost  -3476.81\n",
      "Pre-training layer 1, epoch 449, cost  -3476.8\n",
      "Pre-training layer 1, epoch 450, cost  -3476.8\n",
      "Pre-training layer 1, epoch 451, cost  -3476.77\n",
      "Pre-training layer 1, epoch 452, cost  -3476.78\n",
      "Pre-training layer 1, epoch 453, cost  -3476.77\n",
      "Pre-training layer 1, epoch 454, cost  -3476.81\n",
      "Pre-training layer 1, epoch 455, cost  -3476.84\n",
      "Pre-training layer 1, epoch 456, cost  -3476.79\n",
      "Pre-training layer 1, epoch 457, cost  -3476.8\n",
      "Pre-training layer 1, epoch 458, cost  -3476.78\n",
      "Pre-training layer 1, epoch 459, cost  -3476.81\n",
      "Pre-training layer 1, epoch 460, cost  -3476.8\n",
      "Pre-training layer 1, epoch 461, cost  -3476.81\n",
      "Pre-training layer 1, epoch 462, cost  -3476.83\n",
      "Pre-training layer 1, epoch 463, cost  -3476.82\n",
      "Pre-training layer 1, epoch 464, cost  -3476.79\n",
      "Pre-training layer 1, epoch 465, cost  -3476.77\n",
      "Pre-training layer 1, epoch 466, cost  -3476.79\n",
      "Pre-training layer 1, epoch 467, cost  -3476.83\n",
      "Pre-training layer 1, epoch 468, cost  -3476.77\n",
      "Pre-training layer 1, epoch 469, cost  -3476.82\n",
      "Pre-training layer 1, epoch 470, cost  -3476.87\n",
      "Pre-training layer 1, epoch 471, cost  -3476.84\n",
      "Pre-training layer 1, epoch 472, cost  -3476.79\n",
      "Pre-training layer 1, epoch 473, cost  -3476.82\n",
      "Pre-training layer 1, epoch 474, cost  -3476.78\n",
      "Pre-training layer 1, epoch 475, cost  -3476.83\n",
      "Pre-training layer 1, epoch 476, cost  -3476.83\n",
      "Pre-training layer 1, epoch 477, cost  -3476.82\n",
      "Pre-training layer 1, epoch 478, cost  -3476.79\n",
      "Pre-training layer 1, epoch 479, cost  -3476.81\n",
      "Pre-training layer 1, epoch 480, cost  -3476.8\n",
      "Pre-training layer 1, epoch 481, cost  -3476.78\n",
      "Pre-training layer 1, epoch 482, cost  -3476.85\n",
      "Pre-training layer 1, epoch 483, cost  -3476.81\n",
      "Pre-training layer 1, epoch 484, cost  -3476.83\n",
      "Pre-training layer 1, epoch 485, cost  -3476.86\n",
      "Pre-training layer 1, epoch 486, cost  -3476.83\n",
      "Pre-training layer 1, epoch 487, cost  -3476.83\n",
      "Pre-training layer 1, epoch 488, cost  -3476.84\n",
      "Pre-training layer 1, epoch 489, cost  -3476.83\n",
      "Pre-training layer 1, epoch 490, cost  -3476.8\n",
      "Pre-training layer 1, epoch 491, cost  -3476.78\n",
      "Pre-training layer 1, epoch 492, cost  -3476.82\n",
      "Pre-training layer 1, epoch 493, cost  -3476.79\n",
      "Pre-training layer 1, epoch 494, cost  -3476.8\n",
      "Pre-training layer 1, epoch 495, cost  -3476.8\n",
      "Pre-training layer 1, epoch 496, cost  -3476.84\n",
      "Pre-training layer 1, epoch 497, cost  -3476.81\n",
      "Pre-training layer 1, epoch 498, cost  -3476.77\n",
      "Pre-training layer 1, epoch 499, cost  -3476.76\n",
      "Pre-training layer 2, epoch 0, cost  -59.2564\n",
      "Pre-training layer 2, epoch 1, cost  -4.71189\n",
      "Pre-training layer 2, epoch 2, cost  -2.7937\n",
      "Pre-training layer 2, epoch 3, cost  -2.00132\n",
      "Pre-training layer 2, epoch 4, cost  -1.56711\n",
      "Pre-training layer 2, epoch 5, cost  -1.29096\n",
      "Pre-training layer 2, epoch 6, cost  -1.09888\n",
      "Pre-training layer 2, epoch 7, cost  -0.95804\n",
      "Pre-training layer 2, epoch 8, cost  -0.849486\n",
      "Pre-training layer 2, epoch 9, cost  -0.764554\n",
      "Pre-training layer 2, epoch 10, cost  -0.695577\n",
      "Pre-training layer 2, epoch 11, cost  -0.637981\n",
      "Pre-training layer 2, epoch 12, cost  -0.589103\n",
      "Pre-training layer 2, epoch 13, cost  -0.547453\n",
      "Pre-training layer 2, epoch 14, cost  -0.511977\n",
      "Pre-training layer 2, epoch 15, cost  -0.481298\n",
      "Pre-training layer 2, epoch 16, cost  -0.45466\n",
      "Pre-training layer 2, epoch 17, cost  -0.430549\n",
      "Pre-training layer 2, epoch 18, cost  -0.40887\n",
      "Pre-training layer 2, epoch 19, cost  -0.389448\n",
      "Pre-training layer 2, epoch 20, cost  -0.372044\n",
      "Pre-training layer 2, epoch 21, cost  -0.356927\n",
      "Pre-training layer 2, epoch 22, cost  -0.342996\n",
      "Pre-training layer 2, epoch 23, cost  -0.329813\n",
      "Pre-training layer 2, epoch 24, cost  -0.317848\n",
      "Pre-training layer 2, epoch 25, cost  -0.306905\n",
      "Pre-training layer 2, epoch 26, cost  -0.296678\n",
      "Pre-training layer 2, epoch 27, cost  -0.286785\n",
      "Pre-training layer 2, epoch 28, cost  -0.278082\n",
      "Pre-training layer 2, epoch 29, cost  -0.270135\n",
      "Pre-training layer 2, epoch 30, cost  -0.26256\n",
      "Pre-training layer 2, epoch 31, cost  -0.255676\n",
      "Pre-training layer 2, epoch 32, cost  -0.24918\n",
      "Pre-training layer 2, epoch 33, cost  -0.242974\n",
      "Pre-training layer 2, epoch 34, cost  -0.236874\n",
      "Pre-training layer 2, epoch 35, cost  -0.231349\n",
      "Pre-training layer 2, epoch 36, cost  -0.225974\n",
      "Pre-training layer 2, epoch 37, cost  -0.220878\n",
      "Pre-training layer 2, epoch 38, cost  -0.216167\n",
      "Pre-training layer 2, epoch 39, cost  -0.211685\n",
      "Pre-training layer 2, epoch 40, cost  -0.207487\n",
      "Pre-training layer 2, epoch 41, cost  -0.203452\n",
      "Pre-training layer 2, epoch 42, cost  -0.199476\n",
      "Pre-training layer 2, epoch 43, cost  -0.195663\n",
      "Pre-training layer 2, epoch 44, cost  -0.192009\n",
      "Pre-training layer 2, epoch 45, cost  -0.188728\n",
      "Pre-training layer 2, epoch 46, cost  -0.185409\n",
      "Pre-training layer 2, epoch 47, cost  -0.182321\n",
      "Pre-training layer 2, epoch 48, cost  -0.179326\n",
      "Pre-training layer 2, epoch 49, cost  -0.176564\n",
      "Pre-training layer 2, epoch 50, cost  -0.173783\n",
      "Pre-training layer 2, epoch 51, cost  -0.171166\n",
      "Pre-training layer 2, epoch 52, cost  -0.168622\n",
      "Pre-training layer 2, epoch 53, cost  -0.166233\n",
      "Pre-training layer 2, epoch 54, cost  -0.16384\n",
      "Pre-training layer 2, epoch 55, cost  -0.16158\n",
      "Pre-training layer 2, epoch 56, cost  -0.159299\n",
      "Pre-training layer 2, epoch 57, cost  -0.157128\n",
      "Pre-training layer 2, epoch 58, cost  -0.155138\n",
      "Pre-training layer 2, epoch 59, cost  -0.153115\n",
      "Pre-training layer 2, epoch 60, cost  -0.151208\n",
      "Pre-training layer 2, epoch 61, cost  -0.149321\n",
      "Pre-training layer 2, epoch 62, cost  -0.147564\n",
      "Pre-training layer 2, epoch 63, cost  -0.145867\n",
      "Pre-training layer 2, epoch 64, cost  -0.144164\n",
      "Pre-training layer 2, epoch 65, cost  -0.142489\n",
      "Pre-training layer 2, epoch 66, cost  -0.14094\n",
      "Pre-training layer 2, epoch 67, cost  -0.139452\n",
      "Pre-training layer 2, epoch 68, cost  -0.137964\n",
      "Pre-training layer 2, epoch 69, cost  -0.136501\n",
      "Pre-training layer 2, epoch 70, cost  -0.135083\n",
      "Pre-training layer 2, epoch 71, cost  -0.133733\n",
      "Pre-training layer 2, epoch 72, cost  -0.13247\n",
      "Pre-training layer 2, epoch 73, cost  -0.131168\n",
      "Pre-training layer 2, epoch 74, cost  -0.129875\n",
      "Pre-training layer 2, epoch 75, cost  -0.128731\n",
      "Pre-training layer 2, epoch 76, cost  -0.127565\n",
      "Pre-training layer 2, epoch 77, cost  -0.12644\n",
      "Pre-training layer 2, epoch 78, cost  -0.12531\n",
      "Pre-training layer 2, epoch 79, cost  -0.124196\n",
      "Pre-training layer 2, epoch 80, cost  -0.123112\n",
      "Pre-training layer 2, epoch 81, cost  -0.122096\n",
      "Pre-training layer 2, epoch 82, cost  -0.12106\n",
      "Pre-training layer 2, epoch 83, cost  -0.120015\n",
      "Pre-training layer 2, epoch 84, cost  -0.119091\n",
      "Pre-training layer 2, epoch 85, cost  -0.118176\n",
      "Pre-training layer 2, epoch 86, cost  -0.117225\n",
      "Pre-training layer 2, epoch 87, cost  -0.116296\n",
      "Pre-training layer 2, epoch 88, cost  -0.115425\n",
      "Pre-training layer 2, epoch 89, cost  -0.114579\n",
      "Pre-training layer 2, epoch 90, cost  -0.113739\n",
      "Pre-training layer 2, epoch 91, cost  -0.112954\n",
      "Pre-training layer 2, epoch 92, cost  -0.112156\n",
      "Pre-training layer 2, epoch 93, cost  -0.111391\n",
      "Pre-training layer 2, epoch 94, cost  -0.110631\n",
      "Pre-training layer 2, epoch 95, cost  -0.109803\n",
      "Pre-training layer 2, epoch 96, cost  -0.109074\n",
      "Pre-training layer 2, epoch 97, cost  -0.108343\n",
      "Pre-training layer 2, epoch 98, cost  -0.107648\n",
      "Pre-training layer 2, epoch 99, cost  -0.106969\n",
      "Pre-training layer 2, epoch 100, cost  -0.106277\n",
      "Pre-training layer 2, epoch 101, cost  -0.105622\n",
      "Pre-training layer 2, epoch 102, cost  -0.104975\n",
      "Pre-training layer 2, epoch 103, cost  -0.104405\n",
      "Pre-training layer 2, epoch 104, cost  -0.103808\n",
      "Pre-training layer 2, epoch 105, cost  -0.103216\n",
      "Pre-training layer 2, epoch 106, cost  -0.102645\n",
      "Pre-training layer 2, epoch 107, cost  -0.102061\n",
      "Pre-training layer 2, epoch 108, cost  -0.101485\n",
      "Pre-training layer 2, epoch 109, cost  -0.100886\n",
      "Pre-training layer 2, epoch 110, cost  -0.100294\n",
      "Pre-training layer 2, epoch 111, cost  -0.0997611\n",
      "Pre-training layer 2, epoch 112, cost  -0.0992218\n",
      "Pre-training layer 2, epoch 113, cost  -0.0987098\n",
      "Pre-training layer 2, epoch 114, cost  -0.0982359\n",
      "Pre-training layer 2, epoch 115, cost  -0.0977273\n",
      "Pre-training layer 2, epoch 116, cost  -0.0972021\n",
      "Pre-training layer 2, epoch 117, cost  -0.096729\n",
      "Pre-training layer 2, epoch 118, cost  -0.096221\n",
      "Pre-training layer 2, epoch 119, cost  -0.0957561\n",
      "Pre-training layer 2, epoch 120, cost  -0.0952802\n",
      "Pre-training layer 2, epoch 121, cost  -0.094819\n",
      "Pre-training layer 2, epoch 122, cost  -0.0943339\n",
      "Pre-training layer 2, epoch 123, cost  -0.093885\n",
      "Pre-training layer 2, epoch 124, cost  -0.0934322\n",
      "Pre-training layer 2, epoch 125, cost  -0.0929922\n",
      "Pre-training layer 2, epoch 126, cost  -0.0925648\n",
      "Pre-training layer 2, epoch 127, cost  -0.0921641\n",
      "Pre-training layer 2, epoch 128, cost  -0.0917619\n",
      "Pre-training layer 2, epoch 129, cost  -0.0913596\n",
      "Pre-training layer 2, epoch 130, cost  -0.0909471\n",
      "Pre-training layer 2, epoch 131, cost  -0.090572\n",
      "Pre-training layer 2, epoch 132, cost  -0.0902249\n",
      "Pre-training layer 2, epoch 133, cost  -0.0898512\n",
      "Pre-training layer 2, epoch 134, cost  -0.0894693\n",
      "Pre-training layer 2, epoch 135, cost  -0.0891053\n",
      "Pre-training layer 2, epoch 136, cost  -0.0887464\n",
      "Pre-training layer 2, epoch 137, cost  -0.0883989\n",
      "Pre-training layer 2, epoch 138, cost  -0.0880749\n",
      "Pre-training layer 2, epoch 139, cost  -0.0877133\n",
      "Pre-training layer 2, epoch 140, cost  -0.0873637\n",
      "Pre-training layer 2, epoch 141, cost  -0.0870266\n",
      "Pre-training layer 2, epoch 142, cost  -0.0867054\n",
      "Pre-training layer 2, epoch 143, cost  -0.0863762\n",
      "Pre-training layer 2, epoch 144, cost  -0.0860574\n",
      "Pre-training layer 2, epoch 145, cost  -0.0857394\n",
      "Pre-training layer 2, epoch 146, cost  -0.0854114\n",
      "Pre-training layer 2, epoch 147, cost  -0.0851224\n",
      "Pre-training layer 2, epoch 148, cost  -0.0848584\n",
      "Pre-training layer 2, epoch 149, cost  -0.084577\n",
      "Pre-training layer 2, epoch 150, cost  -0.0842941\n",
      "Pre-training layer 2, epoch 151, cost  -0.0840085\n",
      "Pre-training layer 2, epoch 152, cost  -0.0837299\n",
      "Pre-training layer 2, epoch 153, cost  -0.0834336\n",
      "Pre-training layer 2, epoch 154, cost  -0.0831617\n",
      "Pre-training layer 2, epoch 155, cost  -0.0828957\n",
      "Pre-training layer 2, epoch 156, cost  -0.0826282\n",
      "Pre-training layer 2, epoch 157, cost  -0.082357\n",
      "Pre-training layer 2, epoch 158, cost  -0.0820899\n",
      "Pre-training layer 2, epoch 159, cost  -0.081845\n",
      "Pre-training layer 2, epoch 160, cost  -0.0816008\n",
      "Pre-training layer 2, epoch 161, cost  -0.0813549\n",
      "Pre-training layer 2, epoch 162, cost  -0.0811047\n",
      "Pre-training layer 2, epoch 163, cost  -0.0808422\n",
      "Pre-training layer 2, epoch 164, cost  -0.0805658\n",
      "Pre-training layer 2, epoch 165, cost  -0.0803014\n",
      "Pre-training layer 2, epoch 166, cost  -0.080045\n",
      "Pre-training layer 2, epoch 167, cost  -0.0797988\n",
      "Pre-training layer 2, epoch 168, cost  -0.0795712\n",
      "Pre-training layer 2, epoch 169, cost  -0.0793338\n",
      "Pre-training layer 2, epoch 170, cost  -0.0791076\n",
      "Pre-training layer 2, epoch 171, cost  -0.078854\n",
      "Pre-training layer 2, epoch 172, cost  -0.0786375\n",
      "Pre-training layer 2, epoch 173, cost  -0.0784246\n",
      "Pre-training layer 2, epoch 174, cost  -0.0782061\n",
      "Pre-training layer 2, epoch 175, cost  -0.0779747\n",
      "Pre-training layer 2, epoch 176, cost  -0.0777607\n",
      "Pre-training layer 2, epoch 177, cost  -0.0775534\n",
      "Pre-training layer 2, epoch 178, cost  -0.0773174\n",
      "Pre-training layer 2, epoch 179, cost  -0.0771094\n",
      "Pre-training layer 2, epoch 180, cost  -0.0769087\n",
      "Pre-training layer 2, epoch 181, cost  -0.076713\n",
      "Pre-training layer 2, epoch 182, cost  -0.0765088\n",
      "Pre-training layer 2, epoch 183, cost  -0.0763281\n",
      "Pre-training layer 2, epoch 184, cost  -0.0761429\n",
      "Pre-training layer 2, epoch 185, cost  -0.0759366\n",
      "Pre-training layer 2, epoch 186, cost  -0.0757403\n",
      "Pre-training layer 2, epoch 187, cost  -0.0755474\n",
      "Pre-training layer 2, epoch 188, cost  -0.0753495\n",
      "Pre-training layer 2, epoch 189, cost  -0.0751533\n",
      "Pre-training layer 2, epoch 190, cost  -0.0749641\n",
      "Pre-training layer 2, epoch 191, cost  -0.0747689\n",
      "Pre-training layer 2, epoch 192, cost  -0.0745933\n",
      "Pre-training layer 2, epoch 193, cost  -0.0744062\n",
      "Pre-training layer 2, epoch 194, cost  -0.0742357\n",
      "Pre-training layer 2, epoch 195, cost  -0.0740591\n",
      "Pre-training layer 2, epoch 196, cost  -0.0738791\n",
      "Pre-training layer 2, epoch 197, cost  -0.0737078\n",
      "Pre-training layer 2, epoch 198, cost  -0.0735415\n",
      "Pre-training layer 2, epoch 199, cost  -0.0733847\n",
      "Pre-training layer 2, epoch 200, cost  -0.0732144\n",
      "Pre-training layer 2, epoch 201, cost  -0.0730528\n",
      "Pre-training layer 2, epoch 202, cost  -0.0728973\n",
      "Pre-training layer 2, epoch 203, cost  -0.0727394\n",
      "Pre-training layer 2, epoch 204, cost  -0.0725825\n",
      "Pre-training layer 2, epoch 205, cost  -0.0724273\n",
      "Pre-training layer 2, epoch 206, cost  -0.0722623\n",
      "Pre-training layer 2, epoch 207, cost  -0.0721078\n",
      "Pre-training layer 2, epoch 208, cost  -0.0719702\n",
      "Pre-training layer 2, epoch 209, cost  -0.0718156\n",
      "Pre-training layer 2, epoch 210, cost  -0.0716704\n",
      "Pre-training layer 2, epoch 211, cost  -0.0715364\n",
      "Pre-training layer 2, epoch 212, cost  -0.0713941\n",
      "Pre-training layer 2, epoch 213, cost  -0.0712539\n",
      "Pre-training layer 2, epoch 214, cost  -0.0711151\n",
      "Pre-training layer 2, epoch 215, cost  -0.0709762\n",
      "Pre-training layer 2, epoch 216, cost  -0.0708351\n",
      "Pre-training layer 2, epoch 217, cost  -0.070694\n",
      "Pre-training layer 2, epoch 218, cost  -0.0705501\n",
      "Pre-training layer 2, epoch 219, cost  -0.070414\n",
      "Pre-training layer 2, epoch 220, cost  -0.0702893\n",
      "Pre-training layer 2, epoch 221, cost  -0.070154\n",
      "Pre-training layer 2, epoch 222, cost  -0.0700172\n",
      "Pre-training layer 2, epoch 223, cost  -0.0698878\n",
      "Pre-training layer 2, epoch 224, cost  -0.0697638\n",
      "Pre-training layer 2, epoch 225, cost  -0.0696347\n",
      "Pre-training layer 2, epoch 226, cost  -0.0695257\n",
      "Pre-training layer 2, epoch 227, cost  -0.069396\n",
      "Pre-training layer 2, epoch 228, cost  -0.0692612\n",
      "Pre-training layer 2, epoch 229, cost  -0.0691335\n",
      "Pre-training layer 2, epoch 230, cost  -0.0690138\n",
      "Pre-training layer 2, epoch 231, cost  -0.0688953\n",
      "Pre-training layer 2, epoch 232, cost  -0.068776\n",
      "Pre-training layer 2, epoch 233, cost  -0.0686563\n",
      "Pre-training layer 2, epoch 234, cost  -0.0685457\n",
      "Pre-training layer 2, epoch 235, cost  -0.0684287\n",
      "Pre-training layer 2, epoch 236, cost  -0.0683111\n",
      "Pre-training layer 2, epoch 237, cost  -0.0681929\n",
      "Pre-training layer 2, epoch 238, cost  -0.0680795\n",
      "Pre-training layer 2, epoch 239, cost  -0.0679676\n",
      "Pre-training layer 2, epoch 240, cost  -0.0678691\n",
      "Pre-training layer 2, epoch 241, cost  -0.0677646\n",
      "Pre-training layer 2, epoch 242, cost  -0.0676479\n",
      "Pre-training layer 2, epoch 243, cost  -0.0675337\n",
      "Pre-training layer 2, epoch 244, cost  -0.0674323\n",
      "Pre-training layer 2, epoch 245, cost  -0.0673321\n",
      "Pre-training layer 2, epoch 246, cost  -0.0672262\n",
      "Pre-training layer 2, epoch 247, cost  -0.06713\n",
      "Pre-training layer 2, epoch 248, cost  -0.0670264\n",
      "Pre-training layer 2, epoch 249, cost  -0.0669247\n",
      "Pre-training layer 2, epoch 250, cost  -0.0668269\n",
      "Pre-training layer 2, epoch 251, cost  -0.0667301\n",
      "Pre-training layer 2, epoch 252, cost  -0.0666265\n",
      "Pre-training layer 2, epoch 253, cost  -0.0665269\n",
      "Pre-training layer 2, epoch 254, cost  -0.0664247\n",
      "Pre-training layer 2, epoch 255, cost  -0.0663207\n",
      "Pre-training layer 2, epoch 256, cost  -0.0662235\n",
      "Pre-training layer 2, epoch 257, cost  -0.0661222\n",
      "Pre-training layer 2, epoch 258, cost  -0.0660243\n",
      "Pre-training layer 2, epoch 259, cost  -0.0659154\n",
      "Pre-training layer 2, epoch 260, cost  -0.0658152\n",
      "Pre-training layer 2, epoch 261, cost  -0.0657207\n",
      "Pre-training layer 2, epoch 262, cost  -0.0656343\n",
      "Pre-training layer 2, epoch 263, cost  -0.0655502\n",
      "Pre-training layer 2, epoch 264, cost  -0.0654572\n",
      "Pre-training layer 2, epoch 265, cost  -0.0653671\n",
      "Pre-training layer 2, epoch 266, cost  -0.0652775\n",
      "Pre-training layer 2, epoch 267, cost  -0.0651908\n",
      "Pre-training layer 2, epoch 268, cost  -0.0650922\n",
      "Pre-training layer 2, epoch 269, cost  -0.0649958\n",
      "Pre-training layer 2, epoch 270, cost  -0.0648999\n",
      "Pre-training layer 2, epoch 271, cost  -0.0648029\n",
      "Pre-training layer 2, epoch 272, cost  -0.064715\n",
      "Pre-training layer 2, epoch 273, cost  -0.0646236\n",
      "Pre-training layer 2, epoch 274, cost  -0.0645324\n",
      "Pre-training layer 2, epoch 275, cost  -0.0644404\n",
      "Pre-training layer 2, epoch 276, cost  -0.0643544\n",
      "Pre-training layer 2, epoch 277, cost  -0.0642661\n",
      "Pre-training layer 2, epoch 278, cost  -0.0641938\n",
      "Pre-training layer 2, epoch 279, cost  -0.0641176\n",
      "Pre-training layer 2, epoch 280, cost  -0.0640335\n",
      "Pre-training layer 2, epoch 281, cost  -0.0639507\n",
      "Pre-training layer 2, epoch 282, cost  -0.0638718\n",
      "Pre-training layer 2, epoch 283, cost  -0.063796\n",
      "Pre-training layer 2, epoch 284, cost  -0.0637246\n",
      "Pre-training layer 2, epoch 285, cost  -0.0636533\n",
      "Pre-training layer 2, epoch 286, cost  -0.0635781\n",
      "Pre-training layer 2, epoch 287, cost  -0.0634992\n",
      "Pre-training layer 2, epoch 288, cost  -0.0634209\n",
      "Pre-training layer 2, epoch 289, cost  -0.0633457\n",
      "Pre-training layer 2, epoch 290, cost  -0.0632664\n",
      "Pre-training layer 2, epoch 291, cost  -0.0631985\n",
      "Pre-training layer 2, epoch 292, cost  -0.0631265\n",
      "Pre-training layer 2, epoch 293, cost  -0.0630499\n",
      "Pre-training layer 2, epoch 294, cost  -0.0629791\n",
      "Pre-training layer 2, epoch 295, cost  -0.0628999\n",
      "Pre-training layer 2, epoch 296, cost  -0.0628184\n",
      "Pre-training layer 2, epoch 297, cost  -0.0627407\n",
      "Pre-training layer 2, epoch 298, cost  -0.0626686\n",
      "Pre-training layer 2, epoch 299, cost  -0.0626004\n",
      "Pre-training layer 2, epoch 300, cost  -0.0625276\n",
      "Pre-training layer 2, epoch 301, cost  -0.0624637\n",
      "Pre-training layer 2, epoch 302, cost  -0.0623983\n",
      "Pre-training layer 2, epoch 303, cost  -0.0623362\n",
      "Pre-training layer 2, epoch 304, cost  -0.0622696\n",
      "Pre-training layer 2, epoch 305, cost  -0.0622003\n",
      "Pre-training layer 2, epoch 306, cost  -0.062132\n",
      "Pre-training layer 2, epoch 307, cost  -0.0620666\n",
      "Pre-training layer 2, epoch 308, cost  -0.0619995\n",
      "Pre-training layer 2, epoch 309, cost  -0.0619328\n",
      "Pre-training layer 2, epoch 310, cost  -0.0618694\n",
      "Pre-training layer 2, epoch 311, cost  -0.0618024\n",
      "Pre-training layer 2, epoch 312, cost  -0.0617356\n",
      "Pre-training layer 2, epoch 313, cost  -0.0616655\n",
      "Pre-training layer 2, epoch 314, cost  -0.0615918\n",
      "Pre-training layer 2, epoch 315, cost  -0.0615285\n",
      "Pre-training layer 2, epoch 316, cost  -0.0614615\n",
      "Pre-training layer 2, epoch 317, cost  -0.0613964\n",
      "Pre-training layer 2, epoch 318, cost  -0.0613286\n",
      "Pre-training layer 2, epoch 319, cost  -0.0612651\n",
      "Pre-training layer 2, epoch 320, cost  -0.0612044\n",
      "Pre-training layer 2, epoch 321, cost  -0.0611455\n",
      "Pre-training layer 2, epoch 322, cost  -0.0610854\n",
      "Pre-training layer 2, epoch 323, cost  -0.0610192\n",
      "Pre-training layer 2, epoch 324, cost  -0.0609568\n",
      "Pre-training layer 2, epoch 325, cost  -0.0608914\n",
      "Pre-training layer 2, epoch 326, cost  -0.0608289\n",
      "Pre-training layer 2, epoch 327, cost  -0.0607701\n",
      "Pre-training layer 2, epoch 328, cost  -0.0607151\n",
      "Pre-training layer 2, epoch 329, cost  -0.0606513\n",
      "Pre-training layer 2, epoch 330, cost  -0.0605919\n",
      "Pre-training layer 2, epoch 331, cost  -0.0605318\n",
      "Pre-training layer 2, epoch 332, cost  -0.0604783\n",
      "Pre-training layer 2, epoch 333, cost  -0.0604285\n",
      "Pre-training layer 2, epoch 334, cost  -0.0603661\n",
      "Pre-training layer 2, epoch 335, cost  -0.0603095\n",
      "Pre-training layer 2, epoch 336, cost  -0.0602528\n",
      "Pre-training layer 2, epoch 337, cost  -0.0602004\n",
      "Pre-training layer 2, epoch 338, cost  -0.0601461\n",
      "Pre-training layer 2, epoch 339, cost  -0.0600888\n",
      "Pre-training layer 2, epoch 340, cost  -0.06004\n",
      "Pre-training layer 2, epoch 341, cost  -0.0599852\n",
      "Pre-training layer 2, epoch 342, cost  -0.0599308\n",
      "Pre-training layer 2, epoch 343, cost  -0.0598754\n",
      "Pre-training layer 2, epoch 344, cost  -0.0598255\n",
      "Pre-training layer 2, epoch 345, cost  -0.0597722\n",
      "Pre-training layer 2, epoch 346, cost  -0.0597201\n",
      "Pre-training layer 2, epoch 347, cost  -0.0596694\n",
      "Pre-training layer 2, epoch 348, cost  -0.0596232\n",
      "Pre-training layer 2, epoch 349, cost  -0.0595723\n",
      "Pre-training layer 2, epoch 350, cost  -0.0595188\n",
      "Pre-training layer 2, epoch 351, cost  -0.0594643\n",
      "Pre-training layer 2, epoch 352, cost  -0.0594103\n",
      "Pre-training layer 2, epoch 353, cost  -0.0593584\n",
      "Pre-training layer 2, epoch 354, cost  -0.0593043\n",
      "Pre-training layer 2, epoch 355, cost  -0.0592472\n",
      "Pre-training layer 2, epoch 356, cost  -0.0592019\n",
      "Pre-training layer 2, epoch 357, cost  -0.0591505\n",
      "Pre-training layer 2, epoch 358, cost  -0.0591028\n",
      "Pre-training layer 2, epoch 359, cost  -0.059054\n",
      "Pre-training layer 2, epoch 360, cost  -0.0590036\n",
      "Pre-training layer 2, epoch 361, cost  -0.0589566\n",
      "Pre-training layer 2, epoch 362, cost  -0.0589119\n",
      "Pre-training layer 2, epoch 363, cost  -0.0588631\n",
      "Pre-training layer 2, epoch 364, cost  -0.0588209\n",
      "Pre-training layer 2, epoch 365, cost  -0.0587719\n",
      "Pre-training layer 2, epoch 366, cost  -0.0587213\n",
      "Pre-training layer 2, epoch 367, cost  -0.0586732\n",
      "Pre-training layer 2, epoch 368, cost  -0.0586303\n",
      "Pre-training layer 2, epoch 369, cost  -0.0585862\n",
      "Pre-training layer 2, epoch 370, cost  -0.0585401\n",
      "Pre-training layer 2, epoch 371, cost  -0.0585003\n",
      "Pre-training layer 2, epoch 372, cost  -0.0584558\n",
      "Pre-training layer 2, epoch 373, cost  -0.0584049\n",
      "Pre-training layer 2, epoch 374, cost  -0.0583524\n",
      "Pre-training layer 2, epoch 375, cost  -0.0583063\n",
      "Pre-training layer 2, epoch 376, cost  -0.0582615\n",
      "Pre-training layer 2, epoch 377, cost  -0.0582184\n",
      "Pre-training layer 2, epoch 378, cost  -0.0581778\n",
      "Pre-training layer 2, epoch 379, cost  -0.0581395\n",
      "Pre-training layer 2, epoch 380, cost  -0.0580926\n",
      "Pre-training layer 2, epoch 381, cost  -0.0580511\n",
      "Pre-training layer 2, epoch 382, cost  -0.0580081\n",
      "Pre-training layer 2, epoch 383, cost  -0.0579609\n",
      "Pre-training layer 2, epoch 384, cost  -0.0579165\n",
      "Pre-training layer 2, epoch 385, cost  -0.0578755\n",
      "Pre-training layer 2, epoch 386, cost  -0.0578409\n",
      "Pre-training layer 2, epoch 387, cost  -0.0577952\n",
      "Pre-training layer 2, epoch 388, cost  -0.0577527\n",
      "Pre-training layer 2, epoch 389, cost  -0.0577078\n",
      "Pre-training layer 2, epoch 390, cost  -0.0576637\n",
      "Pre-training layer 2, epoch 391, cost  -0.0576265\n",
      "Pre-training layer 2, epoch 392, cost  -0.0575865\n",
      "Pre-training layer 2, epoch 393, cost  -0.0575502\n",
      "Pre-training layer 2, epoch 394, cost  -0.0575143\n",
      "Pre-training layer 2, epoch 395, cost  -0.0574729\n",
      "Pre-training layer 2, epoch 396, cost  -0.0574359\n",
      "Pre-training layer 2, epoch 397, cost  -0.0574022\n",
      "Pre-training layer 2, epoch 398, cost  -0.0573588\n",
      "Pre-training layer 2, epoch 399, cost  -0.0573175\n",
      "Pre-training layer 2, epoch 400, cost  -0.0572793\n",
      "Pre-training layer 2, epoch 401, cost  -0.0572422\n",
      "Pre-training layer 2, epoch 402, cost  -0.0572054\n",
      "Pre-training layer 2, epoch 403, cost  -0.0571669\n",
      "Pre-training layer 2, epoch 404, cost  -0.0571263\n",
      "Pre-training layer 2, epoch 405, cost  -0.0570877\n",
      "Pre-training layer 2, epoch 406, cost  -0.0570456\n",
      "Pre-training layer 2, epoch 407, cost  -0.0570084\n",
      "Pre-training layer 2, epoch 408, cost  -0.0569724\n",
      "Pre-training layer 2, epoch 409, cost  -0.0569405\n",
      "Pre-training layer 2, epoch 410, cost  -0.0569028\n",
      "Pre-training layer 2, epoch 411, cost  -0.0568643\n",
      "Pre-training layer 2, epoch 412, cost  -0.0568266\n",
      "Pre-training layer 2, epoch 413, cost  -0.0567873\n",
      "Pre-training layer 2, epoch 414, cost  -0.0567534\n",
      "Pre-training layer 2, epoch 415, cost  -0.0567149\n",
      "Pre-training layer 2, epoch 416, cost  -0.0566761\n",
      "Pre-training layer 2, epoch 417, cost  -0.0566397\n",
      "Pre-training layer 2, epoch 418, cost  -0.0566\n",
      "Pre-training layer 2, epoch 419, cost  -0.0565627\n",
      "Pre-training layer 2, epoch 420, cost  -0.0565305\n",
      "Pre-training layer 2, epoch 421, cost  -0.0564948\n",
      "Pre-training layer 2, epoch 422, cost  -0.05646\n",
      "Pre-training layer 2, epoch 423, cost  -0.0564255\n",
      "Pre-training layer 2, epoch 424, cost  -0.0563946\n",
      "Pre-training layer 2, epoch 425, cost  -0.056359\n",
      "Pre-training layer 2, epoch 426, cost  -0.0563256\n",
      "Pre-training layer 2, epoch 427, cost  -0.0562977\n",
      "Pre-training layer 2, epoch 428, cost  -0.0562563\n",
      "Pre-training layer 2, epoch 429, cost  -0.0562138\n",
      "Pre-training layer 2, epoch 430, cost  -0.0561794\n",
      "Pre-training layer 2, epoch 431, cost  -0.0561449\n",
      "Pre-training layer 2, epoch 432, cost  -0.0561126\n",
      "Pre-training layer 2, epoch 433, cost  -0.0560755\n",
      "Pre-training layer 2, epoch 434, cost  -0.0560482\n",
      "Pre-training layer 2, epoch 435, cost  -0.056015\n",
      "Pre-training layer 2, epoch 436, cost  -0.0559851\n",
      "Pre-training layer 2, epoch 437, cost  -0.0559597\n",
      "Pre-training layer 2, epoch 438, cost  -0.0559274\n",
      "Pre-training layer 2, epoch 439, cost  -0.0558933\n",
      "Pre-training layer 2, epoch 440, cost  -0.0558617\n",
      "Pre-training layer 2, epoch 441, cost  -0.0558287\n",
      "Pre-training layer 2, epoch 442, cost  -0.0557967\n",
      "Pre-training layer 2, epoch 443, cost  -0.0557651\n",
      "Pre-training layer 2, epoch 444, cost  -0.0557292\n",
      "Pre-training layer 2, epoch 445, cost  -0.0556925\n",
      "Pre-training layer 2, epoch 446, cost  -0.0556591\n",
      "Pre-training layer 2, epoch 447, cost  -0.055628\n",
      "Pre-training layer 2, epoch 448, cost  -0.055598\n",
      "Pre-training layer 2, epoch 449, cost  -0.0555681\n",
      "Pre-training layer 2, epoch 450, cost  -0.0555358\n",
      "Pre-training layer 2, epoch 451, cost  -0.0555068\n",
      "Pre-training layer 2, epoch 452, cost  -0.0554749\n",
      "Pre-training layer 2, epoch 453, cost  -0.055446\n",
      "Pre-training layer 2, epoch 454, cost  -0.0554154\n",
      "Pre-training layer 2, epoch 455, cost  -0.0553831\n",
      "Pre-training layer 2, epoch 456, cost  -0.0553511\n",
      "Pre-training layer 2, epoch 457, cost  -0.0553199\n",
      "Pre-training layer 2, epoch 458, cost  -0.0552912\n",
      "Pre-training layer 2, epoch 459, cost  -0.0552637\n",
      "Pre-training layer 2, epoch 460, cost  -0.0552345\n",
      "Pre-training layer 2, epoch 461, cost  -0.0552086\n",
      "Pre-training layer 2, epoch 462, cost  -0.0551774\n",
      "Pre-training layer 2, epoch 463, cost  -0.0551469\n",
      "Pre-training layer 2, epoch 464, cost  -0.0551143\n",
      "Pre-training layer 2, epoch 465, cost  -0.0550822\n",
      "Pre-training layer 2, epoch 466, cost  -0.0550518\n",
      "Pre-training layer 2, epoch 467, cost  -0.0550231\n",
      "Pre-training layer 2, epoch 468, cost  -0.0549975\n",
      "Pre-training layer 2, epoch 469, cost  -0.0549735\n",
      "Pre-training layer 2, epoch 470, cost  -0.0549457\n",
      "Pre-training layer 2, epoch 471, cost  -0.0549203\n",
      "Pre-training layer 2, epoch 472, cost  -0.0548937\n",
      "Pre-training layer 2, epoch 473, cost  -0.0548659\n",
      "Pre-training layer 2, epoch 474, cost  -0.0548378\n",
      "Pre-training layer 2, epoch 475, cost  -0.0548123\n",
      "Pre-training layer 2, epoch 476, cost  -0.0547903\n",
      "Pre-training layer 2, epoch 477, cost  -0.0547622\n",
      "Pre-training layer 2, epoch 478, cost  -0.054737\n",
      "Pre-training layer 2, epoch 479, cost  -0.054711\n",
      "Pre-training layer 2, epoch 480, cost  -0.0546835\n",
      "Pre-training layer 2, epoch 481, cost  -0.0546517\n",
      "Pre-training layer 2, epoch 482, cost  -0.0546248\n",
      "Pre-training layer 2, epoch 483, cost  -0.0545995\n",
      "Pre-training layer 2, epoch 484, cost  -0.0545711\n",
      "Pre-training layer 2, epoch 485, cost  -0.0545441\n",
      "Pre-training layer 2, epoch 486, cost  -0.0545198\n",
      "Pre-training layer 2, epoch 487, cost  -0.0544954\n",
      "Pre-training layer 2, epoch 488, cost  -0.0544698\n",
      "Pre-training layer 2, epoch 489, cost  -0.0544461\n",
      "Pre-training layer 2, epoch 490, cost  -0.0544213\n",
      "Pre-training layer 2, epoch 491, cost  -0.0543971\n",
      "Pre-training layer 2, epoch 492, cost  -0.0543737\n",
      "Pre-training layer 2, epoch 493, cost  -0.054346\n",
      "Pre-training layer 2, epoch 494, cost  -0.0543225\n",
      "Pre-training layer 2, epoch 495, cost  -0.0543006\n",
      "Pre-training layer 2, epoch 496, cost  -0.0542744\n",
      "Pre-training layer 2, epoch 497, cost  -0.0542526\n",
      "Pre-training layer 2, epoch 498, cost  -0.054227\n",
      "Pre-training layer 2, epoch 499, cost  -0.0542018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/theano/scan_module/scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "pretraining_epochs = 500\n",
    "batch_count = shared_x.get_value(borrow=True).shape[0] / batch_size\n",
    "\n",
    "pretraining_fns = dbn.pretraining_functions(train_set_x=shared_x, batch_size=batch_size, k=10)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "## Pre-train layer-wise\n",
    "for i in xrange(dbn.n_layers):\n",
    "    # go through pretraining epochs\n",
    "    for epoch in xrange(pretraining_epochs):\n",
    "        # go through the training set\n",
    "        c = []\n",
    "        for batch_index in xrange(batch_count):\n",
    "            c.append(pretraining_fns[i](index=batch_index, lr=0.01))\n",
    "        print 'Pre-training layer %i, epoch %d, cost ' % (i, epoch),\n",
    "        print np.mean(c)\n",
    "\n",
    "end_time = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_gen = dbn.get_output_generator(shared_x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_representation = output_gen()\n",
    "out_representation = reduce(lambda x, y: list(x) + list(y), out_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  3.58425919e-03,   9.99995470e-01,   4.19216696e-03,\n",
       "          1.00000000e+00,   9.99999404e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.99998927e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          6.46679755e-03,   3.75170680e-03,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          5.14588645e-03,   1.00000000e+00,   1.34601840e-03,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.60428125e-03,   1.40830530e-02,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   9.99998331e-01,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          4.37874384e-02,   4.96011740e-03,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.99999642e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.99999046e-01,   9.99999642e-01,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          2.01000855e-03,   6.57978095e-03,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.99999523e-01,   1.00000000e+00,\n",
       "          9.99995947e-01,   1.00000000e+00,   6.24038838e-03,\n",
       "          1.00000000e+00,   9.99999642e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.99999523e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          9.99998450e-01,   1.00000000e+00,   5.50776673e-03,\n",
       "          7.37618702e-03,   9.99998331e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          6.49494864e-03,   1.00000000e+00,   1.24244494e-02,\n",
       "          2.88856478e-04,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00], dtype=float32),\n",
       " array([  3.58428969e-03,   9.99995470e-01,   4.19217488e-03,\n",
       "          1.00000000e+00,   9.99999404e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.99998927e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          6.46685855e-03,   3.75175639e-03,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          5.14592044e-03,   1.00000000e+00,   1.34603714e-03,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.60429801e-03,   1.40831769e-02,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   9.99998331e-01,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          4.37876843e-02,   4.96014999e-03,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.99999642e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.99999046e-01,   9.99999642e-01,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          2.01002322e-03,   6.57989504e-03,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.99999523e-01,   1.00000000e+00,\n",
       "          9.99995947e-01,   1.00000000e+00,   6.24044938e-03,\n",
       "          1.00000000e+00,   9.99999642e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.99999523e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          9.99998450e-01,   1.00000000e+00,   5.50780632e-03,\n",
       "          7.37621123e-03,   9.99998331e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          6.49498263e-03,   1.00000000e+00,   1.24245221e-02,\n",
       "          2.88859126e-04,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_representation[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
