{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match movie titles in Movielens and Wikipedia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_csv(\"data/ml-20m/movies.csv\")\n",
    "\n",
    "def extract_year(x):\n",
    "    match = re.search(r'.*\\(([0-9]{4})\\)', x.title)\n",
    "    if(match is None):\n",
    "        year = 0\n",
    "    else:\n",
    "        year = match.group(1)\n",
    "    return int(year)\n",
    "\n",
    "movies['year'] = movies.apply(extract_year, axis=1)\n",
    "\n",
    "#movies.year.plot(kind='hist', bins=range(1900, 2020, 5)).set_title(\"Movies per year\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "def fuzzy_find_matching_index(string, string_list):\n",
    "    fuzzy_match, similarity_pct = process.extractOne(string, string_list)\n",
    "\n",
    "    # Boost the similarity of long strings\n",
    "    if(similarity_pct >= 90):\n",
    "        similarity_pct += len(string) / 4\n",
    "        \n",
    "    if(similarity_pct >= 95): # Take only the ones with high similarity\n",
    "        print(string, \"\\t\\t\", fuzzy_match, \"\\t\\t\", similarity_pct)\n",
    "        return string_list.index(fuzzy_match)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def create_title_map_for_year(ml20m_movies, year):\n",
    "    wiki_plots = pd.read_table(\"data/wikipedia/wikipedia_plots_%d.csv\" % year)\n",
    "    wiki_titles = wiki_plots.apply(lambda x: x.title + \"(%d)\" % x.year, axis=1)\n",
    "    titlemap = ml20m_movies[ml20m_movies.year == year].title.apply(lambda s: fuzzy_find_matching_index(s, list(wiki_titles)))\n",
    "    titlemap = titlemap.dropna()\n",
    "    return titlemap.astype(int).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#yeardicts = {}\n",
    "#for y in range(2000, 2016):\n",
    "#    yeardicts[y] = create_title_map_for_year(movies, y)\n",
    "pref = pd.read_csv(\"data/output/pref_vectors.csv\")\n",
    "content = pd.read_csv(\"data/output/content_vectors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wiki_titles = content.title.apply(lambda x: x.decode('utf-8'))\n",
    "titlemap = movies.title.apply(lambda title: fuzzy_find_matching_index(title, list(wiki_titles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('titlemap.pickle', 'wb') as f:\n",
    "    pickle.dump(yeardicts, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
